{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthagrowl/Offensive-Hate-Speech-Detection/blob/main/offensive_speech_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exg_V5Bvd0f6"
      },
      "source": [
        "# Offensive/Hate Speech Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxcku2kvd0f9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBkLwoENd0gC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YW-Jprad0gD"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X3CG0bHd0gE"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('dataset.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt1DtloXd0gF",
        "outputId": "3a6f6744-7ac8-4c25-a34d-231c3dd6192d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>hate_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  hate_speech\n",
              "0  Explanation\\nWhy the edits made under my usern...            0\n",
              "1  D'aww! He matches this background colour I'm s...            0\n",
              "2  Hey man, I'm really not trying to edit war. It...            0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...            0\n",
              "4  You, sir, are my hero. Any chance you remember...            0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArE4j00qd0gH",
        "outputId": "a83907dc-004a-450a-9e4a-a5e4f5c83a6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(159571, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQxgWpgd0gI",
        "outputId": "39ffcbda-577f-4a85-f7fc-bfe32b9e092c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   comment      159571 non-null  object\n",
            " 1   hate_speech  159571 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQoEB_xgd0gI",
        "outputId": "b10c73d9-257f-4474-dac9-bc29c376fda8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "comment        0.0\n",
              "hate_speech    0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check the percentage of nan values \n",
        "data.isna().sum() / len(data) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA9lmzQ2d0gJ"
      },
      "source": [
        "### Visualisation and Distrubution of the speech\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGbBEHxyd0gK",
        "outputId": "c8478e30-4eb2-426b-979e-d457458018c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='hate_speech', ylabel='count'>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAEHCAYAAAA6SeWmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXjUlEQVR4nO3df9BeZX3n8ffHRBSrSJCU0gRMVlPdiL8gQlZ3dhyxEGxrmFYsjC7BZsx2xK6722qh3TU7KDO6ustKi8ymEkkch4hol+wuNmairrtqIEHkR0CWp1BNMmBSwg+3Vpmw3/3jvh57n8cnyR3gfu48D+/XzJn7nO91nXOukxm4P8/5daeqkCRJGvecUQ9AkiQdWQwHkiSpw3AgSZI6DAeSJKnDcCBJkjpmj3oAR4rjjz++FixYMOphSJI0JW699da/raq5k7UZDpoFCxawffv2UQ9DkqQpkeQHB2rzsoIkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6vANiUN22gfXj3oI0jPi1k9cOOohSJoiQztzkGRtkj1J7pqk7Q+TVJLj23KSXJlkLMkdSU7t67siyX1tWtFXPy3JnW2dK5Ok1Y9Lsrn135xkzrCOUZKkmWiYlxWuBZZNLCY5CTgL+GFf+RxgUZtWAVe3vscBq4EzgNOB1X1f9lcD7+1bb3xflwBbqmoRsKUtS5KkAQ0tHFTVN4F9kzRdAXwIqL7acmB99WwFjk1yInA2sLmq9lXVI8BmYFlrO6aqtlZVAeuBc/u2ta7Nr+urS5KkAUzpDYlJlgO7q+r2CU3zgJ19y7ta7WD1XZPUAU6oqgfb/EPACc/M6CVJenaYshsSk7wA+BN6lxSmRFVVkjpQe5JV9C5jcPLJJ0/VsCRJOqJN5ZmDlwELgduT/A0wH/hukl8BdgMn9fWd32oHq8+fpA7wo3bZgfa550ADqqo1VbWkqpbMnTv3aRyaJEkzx5SFg6q6s6p+uaoWVNUCepcCTq2qh4CNwIXtqYWlwGPt0sAm4Kwkc9qNiGcBm1rb40mWtqcULgRubLvaCIw/1bCiry5JkgYwzEcZrwO+A7wiya4kKw/S/SbgfmAM+AvgfQBVtQ/4CLCtTZe1Gq3PZ9o6fw18pdU/Bvx6kvuAt7ZlSZI0oKHdc1BVFxyifUHffAEXH6DfWmDtJPXtwCmT1B8GzjzM4UqSpMbXJ0uSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6hhaOEiyNsmeJHf11T6R5PtJ7kjyl0mO7Wu7NMlYknuTnN1XX9ZqY0ku6asvTHJzq38hyVGt/ry2PNbaFwzrGCVJmomGeebgWmDZhNpm4JSqeg3wf4BLAZIsBs4HXtXW+XSSWUlmAVcB5wCLgQtaX4CPA1dU1cuBR4CVrb4SeKTVr2j9JEnSgIYWDqrqm8C+CbWvVtX+trgVmN/mlwMbqupnVfUAMAac3qaxqrq/qp4ANgDLkwR4C3BDW38dcG7ftta1+RuAM1t/SZI0gFHec/B7wFfa/DxgZ1/brlY7UP0lwKN9QWO83tlWa3+s9ZckSQMYSThI8qfAfuDzo9h/3zhWJdmeZPvevXtHORRJko4YUx4OklwE/CbwrqqqVt4NnNTXbX6rHaj+MHBsktkT6p1ttfYXt/6/oKrWVNWSqloyd+7cp3lkkiTNDFMaDpIsAz4EvL2qftLXtBE4vz1psBBYBNwCbAMWtScTjqJ30+LGFiq+Dryjrb8CuLFvWyva/DuAr/WFEEmSdAizD93lqUlyHfBm4Pgku4DV9J5OeB6wud0juLWqfr+qdiS5Hrib3uWGi6vqybad9wObgFnA2qra0Xbxx8CGJB8FbgOuafVrgM8lGaN3Q+T5wzpGSZJmoqGFg6q6YJLyNZPUxvtfDlw+Sf0m4KZJ6vfTe5phYv2nwHmHNVhJkvRzviFRkiR1GA4kSVKH4UCSJHUYDiRJUofhQJIkdRgOJElSh+FAkiR1GA4kSVKH4UCSJHUYDiRJUofhQJIkdRgOJElSh+FAkiR1GA4kSVKH4UCSJHUYDiRJUofhQJIkdRgOJElSh+FAkiR1GA4kSVLH0MJBkrVJ9iS5q692XJLNSe5rn3NaPUmuTDKW5I4kp/ats6L1vy/Jir76aUnubOtcmSQH24ckSRrMMM8cXAssm1C7BNhSVYuALW0Z4BxgUZtWAVdD74seWA2cAZwOrO77sr8aeG/fessOsQ9JkjSAoYWDqvomsG9CeTmwrs2vA87tq6+vnq3AsUlOBM4GNlfVvqp6BNgMLGttx1TV1qoqYP2EbU22D0mSNICpvufghKp6sM0/BJzQ5ucBO/v67Wq1g9V3TVI/2D5+QZJVSbYn2b53796ncDiSJM08I7shsf3FX6PcR1WtqaolVbVk7ty5wxyKJEnTxlSHgx+1SwK0zz2tvhs4qa/f/FY7WH3+JPWD7UOSJA1gqsPBRmD8iYMVwI199QvbUwtLgcfapYFNwFlJ5rQbEc8CNrW2x5MsbU8pXDhhW5PtQ5IkDWD2sDac5DrgzcDxSXbRe+rgY8D1SVYCPwDe2brfBLwNGAN+ArwHoKr2JfkIsK31u6yqxm9yfB+9JyKOBr7SJg6yD0mSNIChhYOquuAATWdO0reAiw+wnbXA2knq24FTJqk/PNk+JEnSYHxDoiRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6hgoHCTZMkhNkiRNfwcNB0men+Q44Pgkc5Ic16YFwLynutMk/zrJjiR3Jbmu7WdhkpuTjCX5QpKjWt/nteWx1r6gbzuXtvq9Sc7uqy9rtbEklzzVcUqS9Gx0qDMH/wK4FXhl+xyfbgT+/KnsMMk84F8CS6rqFGAWcD7wceCKqno58Aiwsq2yEnik1a9o/UiyuK33KmAZ8Okks5LMAq4CzgEWAxe0vpIkaQAHDQdV9amqWgj8UVX9o6pa2KbXVtVTCgfNbODoJLOBFwAPAm8Bbmjt64Bz2/zytkxrPzNJWn1DVf2sqh4AxoDT2zRWVfdX1RPAhtZXkiQNYPYgnarqz5K8EVjQv05VrT/cHVbV7iSfBH4I/D3wVXpnIx6tqv2t2y7+4bLFPGBnW3d/kseAl7T61r5N96+zc0L9jMnGkmQVsArg5JNPPtxDkSRpRhooHCT5HPAy4HvAk61cwGGHgyRz6P0lvxB4FPgivcsCU66q1gBrAJYsWVKjGIMkSUeagcIBsARYXFXPxBfoW4EHqmovQJIvA28Cjk0yu509mA/sbv13AycBu9pliBcDD/fVx/Wvc6C6JEk6hEHfc3AX8CvP0D5/CCxN8oJ278CZwN3A14F3tD4r6N30CLCxLdPav9ZCykbg/PY0w0JgEXALsA1Y1J5+OIreTYsbn6GxS5I04w165uB44O4ktwA/Gy9W1dsPd4dVdXOSG4DvAvuB2+id2v8fwIYkH221a9oq1wCfSzIG7KP3ZU9V7UhyPb1gsR+4uKqeBEjyfmATvSch1lbVjsMdpyRJz1aDhoN//0zutKpWA6snlO+n96TBxL4/Bc47wHYuBy6fpH4TcNPTH6kkSc8+gz6t8D+HPRBJknRkGPRphR/TezoB4CjgucDfVdUxwxqYJEkajUHPHLxofL7vBURLhzUoSZI0Oof9q4zV81+Bsw/VV5IkTT+DXlb47b7F59B778FPhzIiSZI0UoM+rfBbffP7gb/B3yuQJGlGGvSeg/cMeyCSJOnIMNA9B0nmJ/nLJHva9KUk84c9OEmSNPUGvSHxs/ReQfyrbfpvrSZJkmaYQcPB3Kr6bFXtb9O1wNwhjkuSJI3IoOHg4STvTjKrTe+m98uIkiRphhk0HPwe8E7gIeBBer+OeNGQxiRJkkZo0EcZLwNWVNUjAEmOAz5JLzRIkqQZZNAzB68ZDwYAVbUPeP1whiRJkkZp0HDwnCRzxhfamYNBzzpIkqRpZNAv+P8IfCfJF9vyecDlwxmSJEkapUHfkLg+yXbgLa3021V19/CGJUmSRmXgSwMtDBgIJEma4Q77J5slSdLMZjiQJEkdIwkHSY5NckOS7ye5J8k/SXJcks1J7mufc1rfJLkyyViSO5Kc2redFa3/fUlW9NVPS3JnW+fKJBnFcUqSNB2N6szBp4C/qqpXAq8F7gEuAbZU1SJgS1sGOAdY1KZVwNXw88cpVwNnAKcDq/set7waeG/fesum4JgkSZoRpjwcJHkx8M+AawCq6omqehRYDqxr3dYB57b55cD66tkKHJvkROBsYHNV7WsvaNoMLGttx1TV1qoqYH3ftiRJ0iGM4szBQmAv8NkktyX5TJJfAk6oqgdbn4eAE9r8PGBn3/q7Wu1g9V2T1H9BklVJtifZvnfv3qd5WJIkzQyjCAezgVOBq6vq9cDf8Q+XEABof/HXsAdSVWuqaklVLZk711+gliQJRhMOdgG7qurmtnwDvbDwo3ZJgPa5p7XvBk7qW39+qx2sPn+SuiRJGsCUh4OqegjYmeQVrXQmvZcrbQTGnzhYAdzY5jcCF7anFpYCj7XLD5uAs5LMaTcingVsam2PJ1nanlK4sG9bkiTpEEb140l/AHw+yVHA/cB76AWV65OsBH4AvLP1vQl4GzAG/KT1par2JfkIsK31u6z9WiTA+4BrgaOBr7RJkiQNYCThoKq+ByyZpOnMSfoWcPEBtrMWWDtJfTtwytMbpSRJz06+IVGSJHUYDiRJUofhQJIkdRgOJElSh+FAkiR1GA4kSVKH4UCSJHUYDiRJUofhQJIkdRgOJElSh+FAkiR1GA4kSVKH4UCSJHUYDiRJUofhQJIkdRgOJElSh+FAkiR1GA4kSVKH4UCSJHUYDiRJUsfIwkGSWUluS/Lf2/LCJDcnGUvyhSRHtfrz2vJYa1/Qt41LW/3eJGf31Ze12liSS6b84CRJmsZGeebgA8A9fcsfB66oqpcDjwArW30l8EirX9H6kWQxcD7wKmAZ8OkWOGYBVwHnAIuBC1pfSZI0gJGEgyTzgd8APtOWA7wFuKF1WQec2+aXt2Va+5mt/3JgQ1X9rKoeAMaA09s0VlX3V9UTwIbWV5IkDWBUZw7+M/Ah4P+15ZcAj1bV/ra8C5jX5ucBOwFa+2Ot/8/rE9Y5UP0XJFmVZHuS7Xv37n2ahyRJ0sww5eEgyW8Ce6rq1qne90RVtaaqllTVkrlz5456OJIkHRFmj2CfbwLenuRtwPOBY4BPAccmmd3ODswHdrf+u4GTgF1JZgMvBh7uq4/rX+dAdUmSdAhTfuagqi6tqvlVtYDeDYVfq6p3AV8H3tG6rQBubPMb2zKt/WtVVa1+fnuaYSGwCLgF2AYsak8/HNX2sXEKDk2SpBlhFGcODuSPgQ1JPgrcBlzT6tcAn0syBuyj92VPVe1Icj1wN7AfuLiqngRI8n5gEzALWFtVO6b0SCRJmsZGGg6q6hvAN9r8/fSeNJjY56fAeQdY/3Lg8knqNwE3PYNDlSTpWcM3JEqSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6pjycJDkpCRfT3J3kh1JPtDqxyXZnOS+9jmn1ZPkyiRjSe5Icmrftla0/vclWdFXPy3JnW2dK5Nkqo9TkqTpahRnDvYDf1hVi4GlwMVJFgOXAFuqahGwpS0DnAMsatMq4GrohQlgNXAGcDqwejxQtD7v7Vtv2RQclyRJM8KUh4OqerCqvtvmfwzcA8wDlgPrWrd1wLltfjmwvnq2AscmORE4G9hcVfuq6hFgM7CstR1TVVurqoD1fduSJEmHMNJ7DpIsAF4P3AycUFUPtqaHgBPa/DxgZ99qu1rtYPVdk9Qn2/+qJNuTbN+7d+/TOxhJkmaIkYWDJC8EvgT8q6p6vL+t/cVfwx5DVa2pqiVVtWTu3LnD3p0kSdPCSMJBkufSCwafr6ovt/KP2iUB2ueeVt8NnNS3+vxWO1h9/iR1SZI0gFE8rRDgGuCeqvpPfU0bgfEnDlYAN/bVL2xPLSwFHmuXHzYBZyWZ025EPAvY1NoeT7K07evCvm1JkqRDmD2Cfb4J+OfAnUm+12p/AnwMuD7JSuAHwDtb203A24Ax4CfAewCqal+SjwDbWr/Lqmpfm38fcC1wNPCVNkmSpAFMeTioqv8NHOi9A2dO0r+Aiw+wrbXA2knq24FTnsYwJU1zP7zs1aMegvSMOPnDd075Pn1DoiRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkDsOBJEnqMBxIkqQOw4EkSeowHEiSpA7DgSRJ6jAcSJKkjhkbDpIsS3JvkrEkl4x6PJIkTRczMhwkmQVcBZwDLAYuSLJ4tKOSJGl6mJHhADgdGKuq+6vqCWADsHzEY5IkaVqYPeoBDMk8YGff8i7gjImdkqwCVrXF/5vk3ikYm4bjeOBvRz2ImSyfXDHqIejI5H97w7Y6w9rySw/UMFPDwUCqag2wZtTj0NOXZHtVLRn1OKRnG//bm5lm6mWF3cBJfcvzW02SJB3CTA0H24BFSRYmOQo4H9g44jFJkjQtzMjLClW1P8n7gU3ALGBtVe0Y8bA0XF4ekkbD//ZmoFTVqMcgSZKOIDP1soIkSXqKDAeSJKnDcKBpzddkS6ORZG2SPUnuGvVY9MwzHGja8jXZ0khdCywb9SA0HIYDTWe+Jlsakar6JrBv1OPQcBgONJ1N9prseSMaiyTNGIYDSZLUYTjQdOZrsiVpCAwHms58TbYkDYHhQNNWVe0Hxl+TfQ9wva/JlqZGkuuA7wCvSLIrycpRj0nPHF+fLEmSOjxzIEmSOgwHkiSpw3AgSZI6DAeSJKnDcCBJkjoMB5IkqcNwIIkkCw7np3eTnDudfgEzyUVJ/nzU45CmC8OBpKfiXHo/ky1pBjIcSBo3K8lfJNmR5KtJjk7y3iTbktye5EtJXpDkjcDbgU8k+V6Sl7Xpr5LcmuR/JXnlgXaS5Lwkd7VtfrPVLkpyY5JvJLkvyeq+/u9Ockvb139JMqvVz0rynSTfTfLFJC9s9Tck+Xbb/i1JXtQ29attjPcl+Q9D+1eUZgDDgaRxi4CrqupVwKPA7wBfrqo3VNVr6b2iemVVfZveb1h8sKpeV1V/DawB/qCqTgP+CPj0QfbzYeDsts2399VPb/t8DXBekiVJ/jHwu8Cbqup1wJPAu5IcD/xb4K1VdSqwHfg37Tc2vgB8oG3/rcDft+2/rm3r1cDvJun/0S5JfWaPegCSjhgPVNX32vytwALglCQfBY4FXkjvdyw62l/sbwS+mGS8/LyD7OdbwLVJrge+3FffXFUPt21+GfinwH7gNGBb2/bRwB5gKb3LGt9q9aNo7/kHHqyqbQBV9XjbHsCWqnqsLd8NvBTYeah/FOnZyHAgadzP+uafpPdFfC1wblXdnuQi4M2TrPcc4NH2l/0hVdXvJzkD+A3g1iSnjTdN7AoEWFdVl/Y3JPktemHiggn1Vx9k1xOPz///SQfgZQVJB/Mi4MEkzwXe1Vf/cWsb/+v8gSTnAaTntQfaYJKXVdXNVfVhYC8wfnr/15Mcl+Roejc8fgvYArwjyS+3dY9L8lJgK/CmJC9v9V9K8mvAvcCJSd7Q6i9KYgiQDpPhQNLB/DvgZnpf1N/vq28APpjktiQvoxccVia5HdgBLD/INj+R5M726OS3gdtb/RbgS8AdwJeqantV3U3v3oKvJrkD2AycWFV7gYuA61r9O8Arq+oJevcV/Fkby2bg+U/7X0F6lvEnmyWNXLtksaSq3j/qsUjyzIEkSZrAMweShiLJnwLnTSh/saouH8V4JA3OcCBJkjq8rCBJkjoMB5IkqcNwIEmSOgwHkiSp4/8DJ6DV29W5VPkAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize = (8,4))\n",
        "sns.countplot(x = data[\"hate_speech\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwNkq3O-d0gL",
        "outputId": "ee2df8fb-b11d-47e4-c6e3-3c77d9e4d1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class 0 (non hate speech): 89.83%\n",
            "class 1 (hate speech): 10.17%\n"
          ]
        }
      ],
      "source": [
        "print(f'class 0 (non hate speech): {np.sum(data[\"hate_speech\"] == 0) / len(data) *100:.2f}%')\n",
        "print(f'class 1 (hate speech): {np.sum(data[\"hate_speech\"] == 1) / len(data) *100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtE9u8eWd0gM"
      },
      "source": [
        "### Undersampling the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QewWi3Vd0gM"
      },
      "outputs": [],
      "source": [
        "hate_data = data.loc[data.hate_speech == 1]\n",
        "non_hate_data = data.loc[data.hate_speech == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ4Uj6v2d0gN"
      },
      "outputs": [],
      "source": [
        "balanced_non_hate_data = data.loc[np.random.choice(non_hate_data.index, len(hate_data))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYubdoRZd0gO"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([balanced_non_hate_data,hate_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdZDNwRbd0gP",
        "outputId": "6aa6a4ac-6dad-4fd8-c841-43209ab140b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='hate_speech', ylabel='count'>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAEHCAYAAAA3V5XhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXpUlEQVR4nO3dfbCedZ3f8fdHIj4rIEcWk2hSjVp8hghU244rLgR312S2ojBagmZM20Xrdrcq7LamgzKj626p+IDNSgQchxiRXdIWxSzq0ipPB3lMkHIWqiQD5kgA7bpCw377x/2Le5s9JzmE3PfNOdf7NXPPua7v73ddv9+VGTifcz3dqSokSVL3PGnUE5AkSaNhCJAkqaMMAZIkdZQhQJKkjjIESJLUUfNGPYFhO/TQQ2vRokWjnoYkSUNxww03/KSqxqZq61wIWLRoEePj46OehiRJQ5Hkh9O1eTlAkqSOMgRIktRRhgBJkjrKECBJUkcZAiRJ6ihDgCRJHWUIkCSpowwBkiR11MBCQJJ1SbYnuW23+vuT/CDJ5iR/3Fc/M8lEkjuSnNBXX9ZqE0nO6KsvTnJtq38lyYGDOhZJkuaiQb4x8ALgM8BFuwpJfh1YDry6qh5O8rxWPwI4GXg58HzgL5O8pG32WeA3gK3A9Uk2VtUW4BPAOVW1PsnngVXAeQM8nj066oMX7b2TNAvc8MlTRz2Fx+RHZ71y1FOQ9osXfOTWoY85sDMBVXUVsGO38r8BPl5VD7c+21t9ObC+qh6uqruBCeDo9pmoqruq6hFgPbA8SYA3AZe07S8EVgzqWCRJmouGfU/AS4B/1k7j/1WS17X6fOCevn5bW226+nOBB6tq5251SZI0Q8P+AqF5wCHAscDrgA1J/tGgB02yGlgN8IIXvGDQw0mSNCsM+0zAVuDS6rkO+DvgUGAbsLCv34JWm65+P3BQknm71adUVWuramlVLR0bm/LbFCVJ6pxhh4C/AH4doN34dyDwE2AjcHKSpyRZDCwBrgOuB5a0JwEOpHfz4MaqKuDbwNvaflcClw3zQCRJmu0GdjkgycXAG4FDk2wF1gDrgHXtscFHgJXtF/rmJBuALcBO4PSqerTt533AFcABwLqq2tyG+DCwPsnHgBuB8wd1LJIkzUUDCwFVdco0Te+apv/ZwNlT1C8HLp+ifhe9pwckSdI+8I2BkiR1lCFAkqSOMgRIktRRhgBJkjrKECBJUkcZAiRJ6ihDgCRJHWUIkCSpowwBkiR1lCFAkqSOMgRIktRRhgBJkjrKECBJUkcZAiRJ6ihDgCRJHWUIkCSpowwBkiR11MBCQJJ1SbYnuW2Ktj9IUkkObetJcm6SiSS3JDmyr+/KJHe2z8q++lFJbm3bnJskgzoWSZLmokGeCbgAWLZ7MclC4HjgR33lE4El7bMaOK/1PQRYAxwDHA2sSXJw2+Y84L192/2DsSRJ0vQGFgKq6ipgxxRN5wAfAqqvthy4qHquAQ5KcjhwArCpqnZU1QPAJmBZa3t2VV1TVQVcBKwY1LFIkjQXDfWegCTLgW1VdfNuTfOBe/rWt7banupbp6hPN+7qJONJxicnJx/HEUiSNHcMLQQkeTrwh8BHhjXmLlW1tqqWVtXSsbGxYQ8vSdIT0jDPBLwIWAzcnOT/AAuA7yf5NWAbsLCv74JW21N9wRR1SZI0Q0MLAVV1a1U9r6oWVdUieqfwj6yq+4CNwKntKYFjgYeq6l7gCuD4JAe3GwKPB65obT9Ncmx7KuBU4LJhHYskSXPBIB8RvBi4Gnhpkq1JVu2h++XAXcAE8GfA7wJU1Q7go8D17XNWq9H6fKFt89fA1wdxHJIkzVXzBrXjqjplL+2L+pYLOH2afuuAdVPUx4FXPL5ZSpLUXb4xUJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkddTAQkCSdUm2J7mtr/bJJD9IckuSP09yUF/bmUkmktyR5IS++rJWm0hyRl99cZJrW/0rSQ4c1LFIkjQXDfJMwAXAst1qm4BXVNWrgP8NnAmQ5AjgZODlbZvPJTkgyQHAZ4ETgSOAU1pfgE8A51TVi4EHgFUDPBZJkuacgYWAqroK2LFb7ZtVtbOtXgMsaMvLgfVV9XBV3Q1MAEe3z0RV3VVVjwDrgeVJArwJuKRtfyGwYlDHIknSXDTKewLeA3y9Lc8H7ulr29pq09WfCzzYFyh21SVJ0gyNJAQk+SNgJ/DlIY23Osl4kvHJyclhDClJ0hPe0ENAktOA3wLeWVXVytuAhX3dFrTadPX7gYOSzNutPqWqWltVS6tq6djY2H45DkmSZruhhoAky4APAW+tqp/3NW0ETk7ylCSLgSXAdcD1wJL2JMCB9G4e3NjCw7eBt7XtVwKXDes4JEmaCwb5iODFwNXAS5NsTbIK+AzwLGBTkpuSfB6gqjYDG4AtwDeA06vq0XbN/33AFcDtwIbWF+DDwO8nmaB3j8D5gzoWSZLmonl777JvquqUKcrT/qKuqrOBs6eoXw5cPkX9LnpPD0iSpH3gGwMlSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeqogYWAJOuSbE9yW1/tkCSbktzZfh7c6klybpKJJLckObJvm5Wt/51JVvbVj0pya9vm3CQZ1LFIkjQXDfJMwAXAst1qZwBXVtUS4Mq2DnAisKR9VgPnQS80AGuAY4CjgTW7gkPr896+7XYfS5Ik7cHAQkBVXQXs2K28HLiwLV8IrOirX1Q91wAHJTkcOAHYVFU7quoBYBOwrLU9u6quqaoCLurblyRJmoFh3xNwWFXd25bvAw5ry/OBe/r6bW21PdW3TlGfUpLVScaTjE9OTj6+I5AkaY4Y2Y2B7S/4GtJYa6tqaVUtHRsbG8aQkiQ94Q07BPy4ncqn/dze6tuAhX39FrTanuoLpqhLkqQZGnYI2AjsusN/JXBZX/3U9pTAscBD7bLBFcDxSQ5uNwQeD1zR2n6a5Nj2VMCpffuSJEkzMG9QO05yMfBG4NAkW+nd5f9xYEOSVcAPgbe37pcDbwEmgJ8D7waoqh1JPgpc3/qdVVW7bjb8XXpPIDwN+Hr7SJKkGRpYCKiqU6ZpOm6KvgWcPs1+1gHrpqiPA694PHOUJKnLfGOgJEkdZQiQJKmjZhQCklw5k5okSZo99nhPQJKnAk+nd3PfwcCu9/M/mz28nEeSJD3x7e3GwH8F/B7wfOAG/j4E/BT4zOCmJUmSBm2PIaCqPgV8Ksn7q+rTQ5qTJEkaghk9IlhVn07yemBR/zZVddGA5iVJkgZsRiEgyZeAFwE3AY+28q5v75MkSbPQTF8WtBQ4or3UR5IkzQEzfU/AbcCvDXIikiRpuGZ6JuBQYEuS64CHdxWr6q0DmZUkSRq4mYaA/zTISUiSpOGb6dMBfzXoiUiSpOGa6dMBP6P3NADAgcCTgb+pqmcPamKSJGmwZnom4Fm7lpMEWA4cO6hJSZKkwXvM3yJYPX8BnLD/pyNJkoZlppcDfqdv9Un03hvwi4HMSJIkDcVMzwT8dt/nBOBn9C4J7JMk/y7J5iS3Jbk4yVOTLE5ybZKJJF9JcmDr+5S2PtHaF/Xt58xWvyOJZyYkSXoMZnpPwLv314BJ5gP/lt4bCP82yQbgZOAtwDlVtT7J54FVwHnt5wNV9eIkJwOfAN6R5Ii23cvpfcvhXyZ5SVU9OsWwkiRpNzM6E5BkQZI/T7K9fb6WZMHjGHce8LQk84CnA/cCbwIuae0XAiva8vK2Tms/ru/mxPVV9XBV3Q1MAEc/jjlJktQpM70c8EVgI72/uJ8P/LdWe8yqahvwJ8CP6P3yfwi4AXiwqna2bluB+W15PnBP23Zn6//c/voU2/yKJKuTjCcZn5yc3JdpS5I058w0BIxV1Reramf7XACM7cuASQ6m91f8YnqB4hnAsn3Z10xV1dqqWlpVS8fG9mnakiTNOTMNAfcneVeSA9rnXcD9+zjmm4G7q2qyqv4fcCnwBuCgdnkAYAGwrS1vAxYCtPbntLF/WZ9iG0mStBczDQHvAd4O3EfvFP7bgNP2ccwfAccmeXq7tn8csAX4dtsvwErgsra8sa3T2r/VvtJ4I3Bye3pgMbAEuG4f5yRJUufM9AuEzgJWVtUDAEkOoXdd/z2PdcCqujbJJcD3gZ3AjcBa4H8A65N8rNXOb5ucD3wpyQSwg94TAVTV5vZkwZa2n9N9MkCSpJmbaQh41a4AAFBVO5K8dl8Hrao1wJrdyncxxd39VfUL4KRp9nM2cPa+zkOSpC6b6eWAJ7Ub+oBfngmYaYCQJElPQDP9Rf6nwNVJvtrWT8K/wCVJmtVm+sbAi5KM03uhD8DvVNWWwU1LkiQN2oxP6bdf+v7ilyRpjnjMXyUsSZLmBkOAJEkdZQiQJKmjDAGSJHWUIUCSpI4yBEiS1FGGAEmSOsoQIElSRxkCJEnqKEOAJEkdZQiQJKmjDAGSJHXUSEJAkoOSXJLkB0luT/JPkhySZFOSO9vPg1vfJDk3yUSSW5Ic2befla3/nUlWjuJYJEmarUZ1JuBTwDeq6mXAq4HbgTOAK6tqCXBlWwc4EVjSPquB8wCSHAKsAY4BjgbW7AoOkiRp74YeApI8B/jnwPkAVfVIVT0ILAcubN0uBFa05eXARdVzDXBQksOBE4BNVbWjqh4ANgHLhnYgkiTNcqM4E7AYmAS+mOTGJF9I8gzgsKq6t/W5DzisLc8H7unbfmurTVf/B5KsTjKeZHxycnI/HookSbPXKELAPOBI4Lyqei3wN/z9qX8AqqqA2l8DVtXaqlpaVUvHxsb2124lSZrVRhECtgJbq+ratn4JvVDw43aan/Zze2vfBizs235Bq01XlyRJMzD0EFBV9wH3JHlpKx0HbAE2Arvu8F8JXNaWNwKntqcEjgUeapcNrgCOT3JwuyHw+FaTJEkzMG9E474f+HKSA4G7gHfTCyQbkqwCfgi8vfW9HHgLMAH8vPWlqnYk+Shwfet3VlXtGN4hSJI0u40kBFTVTcDSKZqOm6JvAadPs591wLr9OjlJkjrCNwZKktRRhgBJkjrKECBJUkcZAiRJ6ihDgCRJHWUIkCSpowwBkiR1lCFAkqSOMgRIktRRhgBJkjrKECBJUkcZAiRJ6ihDgCRJHWUIkCSpowwBkiR1lCFAkqSOMgRIktRRIwsBSQ5IcmOS/97WFye5NslEkq8kObDVn9LWJ1r7or59nNnqdyQ5YUSHIknSrDTKMwEfAG7vW/8EcE5VvRh4AFjV6quAB1r9nNaPJEcAJwMvB5YBn0tywJDmLknSrDeSEJBkAfCbwBfaeoA3AZe0LhcCK9ry8rZOaz+u9V8OrK+qh6vqbmACOHooByBJ0hwwqjMB/wX4EPB3bf25wINVtbOtbwXmt+X5wD0Arf2h1v+X9Sm2+RVJVicZTzI+OTm5Hw9DkqTZa+ghIMlvAdur6oZhjVlVa6tqaVUtHRsbG9awkiQ9oc0bwZhvAN6a5C3AU4FnA58CDkoyr/21vwDY1vpvAxYCW5PMA54D3N9X36V/G0mStBdDPxNQVWdW1YKqWkTvxr5vVdU7gW8Db2vdVgKXteWNbZ3W/q2qqlY/uT09sBhYAlw3pMOQJGnWG8WZgOl8GFif5GPAjcD5rX4+8KUkE8AOesGBqtqcZAOwBdgJnF5Vjw5/2pIkzU4jDQFV9R3gO235Lqa4u7+qfgGcNM32ZwNnD26GkiTNXb4xUJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkddTQQ0CShUm+nWRLks1JPtDqhyTZlOTO9vPgVk+Sc5NMJLklyZF9+1rZ+t+ZZOWwj0WSpNlsFGcCdgJ/UFVHAMcCpyc5AjgDuLKqlgBXtnWAE4El7bMaOA96oQFYAxwDHA2s2RUcJEnS3g09BFTVvVX1/bb8M+B2YD6wHLiwdbsQWNGWlwMXVc81wEFJDgdOADZV1Y6qegDYBCwb3pFIkjS7jfSegCSLgNcC1wKHVdW9rek+4LC2PB+4p2+zra02XX2qcVYnGU8yPjk5uf8OQJKkWWxkISDJM4GvAb9XVT/tb6uqAmp/jVVVa6tqaVUtHRsb21+7lSRpVhtJCEjyZHoB4MtVdWkr/7id5qf93N7q24CFfZsvaLXp6pIkaQZG8XRAgPOB26vqP/c1bQR23eG/Erisr35qe0rgWOChdtngCuD4JAe3GwKPbzVJkjQD80Yw5huAfwncmuSmVvtD4OPAhiSrgB8Cb29tlwNvASaAnwPvBqiqHUk+Clzf+p1VVTuGcgSSJM0BQw8BVfW/gEzTfNwU/Qs4fZp9rQPW7b/ZSZLUHb4xUJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQIkSeooQ4AkSR1lCJAkqaMMAZIkdZQhQJKkjpr1ISDJsiR3JJlIcsao5yNJ0mwxq0NAkgOAzwInAkcApyQ5YrSzkiRpdpjVIQA4Gpioqruq6hFgPbB8xHOSJGlWmDfqCTxO84F7+ta3Asfs3inJamB1W/2/Se4Ywty0/x0K/GTUk5jr8icrRz0FPTH539+grcmg9vzC6RpmewiYkapaC6wd9Tz0+CQZr6qlo56H1EX+9zc3zfbLAduAhX3rC1pNkiTtxWwPAdcDS5IsTnIgcDKwccRzkiRpVpjVlwOqameS9wFXAAcA66pq84inpcHxko40Ov73NwelqkY9B0mSNAKz/XKAJEnaR4YASZI6yhCgWcHXQ0vDl2Rdku1Jbhv1XDQYhgA94fl6aGlkLgCWjXoSGhxDgGYDXw8tjUBVXQXsGPU8NDiGAM0GU70eev6I5iJJc4YhQJKkjjIEaDbw9dCSNACGAM0Gvh5akgbAEKAnvKraCex6PfTtwAZfDy0NXpKLgauBlybZmmTVqOek/cvXBkuS1FGeCZAkqaMMAZIkdZQhQJKkjjIESJLUUYYASZI6yhAgSVJHGQKkDkmy6LF8LWySFbPpGxuTnJbkM6OehzRbGAIk7ckKel/fLGkOMgRI3XNAkj9LsjnJN5M8Lcl7k1yf5OYkX0vy9CSvB94KfDLJTUle1D7fSHJDkv+Z5GXTDZLkpCS3tX1e1WqnJbksyXeS3JlkTV//dyW5ro31X5Mc0OrHJ7k6yfeTfDXJM1v9dUm+1/Z/XZJntV09v83xziR/PLB/RWkOMARI3bME+GxVvRx4EPgXwKVV9bqqejW9VzOvqqrv0fuOhg9W1Wuq6q+BtcD7q+oo4N8Dn9vDOB8BTmj7fGtf/eg25quAk5IsTfKPgXcAb6iq1wCPAu9McijwH4A3V9WRwDjw++07JL4CfKDt/83A37b9v6bt65XAO5L0f/mUpD7zRj0BSUN3d1Xd1JZvABYBr0jyMeAg4Jn0vqfhV7S/wF8PfDXJrvJT9jDOd4ELkmwALu2rb6qq+9s+LwX+KbATOAq4vu37acB24Fh6lyO+2+oH0t5lD9xbVdcDVNVP2/4Arqyqh9r6FuCFwD17+0eRusgQIHXPw33Lj9L7hXsBsKKqbk5yGvDGKbZ7EvBg+0t9r6rqXyc5BvhN4IYkR+1q2r0rEODCqjqzvyHJb9MLDafsVn/lHobe/fj8/5w0DS8HSAJ4FnBvkicD7+yr/6y17fpr++4kJwGk59XT7TDJi6rq2qr6CDAJ7Dot/xtJDknyNHo3Hn4XuBJ4W5LntW0PSfJC4BrgDUle3OrPSPIS4A7g8CSva/VnJfGXvfQYGQIkAfxH4Fp6v5B/0FdfD3wwyY1JXkQvIKxKcjOwGVi+h31+Msmt7ZHE7wE3t/p1wNeAW4CvVdV4VW2hd+3/m0luATYBh1fVJHAacHGrXw28rKoeoXfd/9NtLpuApz7ufwWpY/wqYUlD0y41LK2q9416LpI8EyBJUmd5JkDS45Lkj4CTdit/tarOHsV8JM2cIUCSpI7ycoAkSR1lCJAkqaMMAZIkdZQhQJKkjvr/7CGpAE1i5u0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize = (8,4))\n",
        "sns.countplot(x = df[\"hate_speech\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeYLbN7Yd0gQ",
        "outputId": "a5bf454d-7d25-4c7c-ca72-fe72aef68478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class 0 (non hate speech): 50.00%\n",
            "class 1 (hate speech): 50.00%\n"
          ]
        }
      ],
      "source": [
        "print(f'class 0 (non hate speech): {np.sum(df[\"hate_speech\"] == 0) / len(df) *100:.2f}%')\n",
        "print(f'class 1 (hate speech): {np.sum(df[\"hate_speech\"] == 1) / len(df) *100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQgdHiR_d0gR"
      },
      "source": [
        "### Data preparation: train-val-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzjsQtXEd0gR"
      },
      "outputs": [],
      "source": [
        "def get_splits(x, y, splits):\n",
        "    \"\"\"\n",
        "    The idea is to use an index list as reference:\n",
        "    To shuffle it randomly:\n",
        "    We need 'splits' to contain 2 values. \n",
        "  \n",
        "    \"\"\"\n",
        "    # Create an index list and shuffle it - use the function random.shuffle\n",
        "    data_len = len(x)\n",
        "    index_list = np.arange(data_len)\n",
        "    np.random.shuffle(index_list)\n",
        "    # Find the two indexes we'll use to cut the lists from the splits\n",
        "    train_cut_index = int(data_len*splits[0])\n",
        "    valid_cut_index = int(data_len*(splits[0]+splits[1]))\n",
        "    #Â Do the cutting (careful: you can't use a list as index for a list - this only works with tensors)\n",
        "    # (you need to use list comprehensions - or go through numpy)\n",
        "    train_x, train_y = np.take(x,index_list[:train_cut_index]),np.take(y,index_list[:train_cut_index])\n",
        "    valid_x, valid_y = np.take(x,index_list[train_cut_index:valid_cut_index]),np.take(y,index_list[train_cut_index:valid_cut_index])\n",
        "    test_x, test_y = np.take(x,index_list[valid_cut_index:]),np.take(y,index_list[valid_cut_index:])\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy5kDt_vd0gT"
      },
      "outputs": [],
      "source": [
        "# Choose the training, validation, testing splits\n",
        "splits = (0.8, 0.1)\n",
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = get_splits(df.comment, df.hate_speech, splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjUXQBtzd0gT"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wrv9Oqad0gU",
        "outputId": "40e1c9bb-271c-49c1-ad3e-cafa54d7d627"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWrkIG4Hd0gV"
      },
      "outputs": [],
      "source": [
        "def clean_and_tokenize(text):\n",
        "    \"\"\"  \n",
        "    Process text function.\n",
        "    Input: text\n",
        "    Output: text_clean: a list of words containing the processed text \n",
        "    \n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "    # remove hyperlinks    \n",
        "    text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n",
        "    # only removing the hash # sign from the word\n",
        "    text = re.sub(r'#', '', text)\n",
        "    # remove numbers, points, \n",
        "    text = re.sub(r'[0-9]+', '',text)\n",
        "    text = re.sub(r'\\.', '', text)\n",
        "    # Remove small words (1 and 2 characters)\n",
        "    text = re.sub(r\"\\b\\w{1,2}\\b\", \"\", text)    \n",
        "    text = text.lower()\n",
        "    # tokenize text\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    text_tokens = tokenizer.tokenize(text)\n",
        "    text_clean = []\n",
        "    \n",
        "    for word in text_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            text_clean.append(stem_word)\n",
        "\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPHvVZH5d0gX",
        "outputId": "0557fd84-4a84-4f71-bc75-11ed7cdd5515"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['love', 'machin', 'learn', 'nchsd', ':)']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_and_tokenize(\"I love machine learning 0 */nchsd<p> :)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogwu-N5Yd0gY"
      },
      "outputs": [],
      "source": [
        "text_len = [len(clean_and_tokenize(s)) for s in df.comment]\n",
        "text_len = [l for l in text_len if l <500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFQ8gQYvd0gY",
        "outputId": "acdcc530-8d77-4644-961c-d8c11dfe6eea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(data=text_len,bins=50)\n",
        "plt.title(\"sentence length distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GgrpSdjd0gZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2R9EH6Jd0gZ"
      },
      "source": [
        "#### Creating the Vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp-gusdWd0gZ"
      },
      "outputs": [],
      "source": [
        "def build_vocab(df, tokenizer,min_freq = 1):\n",
        "    assert min_freq > 0\n",
        "    counter = Counter(['<unk>', '<pad>']*min_freq)\n",
        "    for s in df:\n",
        "        counter.update(tokenizer(s))\n",
        "    v =  vocab(counter,min_freq=min_freq)\n",
        "    unk_token = '<unk>'\n",
        "    v.set_default_index(v[unk_token])\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21dpnwXpd0ga"
      },
      "outputs": [],
      "source": [
        "en_vocab = build_vocab(df.comment,clean_and_tokenize,min_freq=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4x-XpB1d0ga",
        "outputId": "15d25673-b985-41f2-b6ee-09bccc99cc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10863\n"
          ]
        }
      ],
      "source": [
        "print(len(en_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5IyUV1nd0gb"
      },
      "outputs": [],
      "source": [
        "PAD_IDX = en_vocab['<pad>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN7cd1WHd0gb"
      },
      "source": [
        "#### Pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTVe1y2Rd0gc"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data, categories, vocab = None, max_length = 100,min_freq = 5):\n",
        "        # Text data\n",
        "        self.data = data\n",
        "        \n",
        "        # Allow to import a vocabulary (for valid/test datasets, that will use the training vocabulary)\n",
        "        if vocab is not None:\n",
        "            self.vocab = vocab\n",
        "        else:\n",
        "            # If no vocabulary imported, build it\n",
        "            self.vocab = build_vocab(self.data, clean_and_tokenize,min_freq)\n",
        "\n",
        "        # Tokenize the data\n",
        "        # Transform words into lists of indexes\n",
        "        # Transform this list of of indexes into Pytorch Tensor\n",
        "        tensor_data = [ torch.tensor([vocab[w] for w in clean_and_tokenize(sentence)][:max_length]) for sentence in self.data ]\n",
        "        self.tensor_data = pad_sequence(tensor_data, batch_first=True, padding_value = PAD_IDX)\n",
        "        \n",
        "        \n",
        "        # Transform the categories into a FloatTensor\n",
        "        self.tensor_y  = torch.FloatTensor(np.array(categories))\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # The iterator just gets one particular example with its category\n",
        "        # The dataloader will take care of the shuffling and batching\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        return self.tensor_data[idx], self.tensor_y[idx] \n",
        "    \n",
        "    def get_vocab(self):\n",
        "        # A simple way to get the training vocab when building the valid/test \n",
        "        return self.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2jX-Lf4d0gc"
      },
      "outputs": [],
      "source": [
        "training_dataset = TextClassificationDataset(train_x, train_y,en_vocab)\n",
        "valid_dataset = TextClassificationDataset(valid_x, valid_y, en_vocab)\n",
        "test_dataset = TextClassificationDataset(test_x, test_y,en_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c29cN-2Nd0gd"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "## Dataloaders\n",
        "training_dataloader = DataLoader(training_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = 25)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3-crj_hd0ge"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIfPURKad0ge"
      },
      "source": [
        "### Model 1 : Simple averaging model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL-QNWDad0gf"
      },
      "outputs": [],
      "source": [
        "class AveragingModel(nn.Module):    \n",
        "    def __init__(self, embedding_dim, vocabulary_size):\n",
        "        super().__init__()\n",
        "        # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
        "        # Look into the arguments of the nn.Embedding class\n",
        "        self.embeddings = nn.Embedding(vocabulary_size,embedding_dim=embedding_dim,padding_idx= PAD_IDX)\n",
        "        #Â Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.fc1 = nn.Linear(embedding_dim,1)\n",
        "        \n",
        "        # No need for sigmoid, it will be into the criterion ! \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        #Â Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
        "        # First, take the mean of the embeddings of the document\n",
        "        x = self.embeddings(inputs)\n",
        "        x = torch.mean(x,dim=1)\n",
        "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
        "        x = self.fc1(x)\n",
        "        o = torch.squeeze(x,dim=1)\n",
        "        return o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_zolsatd0gf"
      },
      "source": [
        "### Model 2: Pretrained Averaging Model with Glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IsSAWPid0gg",
        "outputId": "2c9cff72-cc21-4612-d23b-6c86b6c5dc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (4.1.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: Cython==0.29.23 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (0.29.23)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (1.18.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqUSDg8Td0gg"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "loaded_glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
        "loaded_glove_embeddings = loaded_glove_model.vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWtK2PoEd0gh",
        "outputId": "77b5edf0-f5ab-472d-ceaa-79ab849002af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10863, 300)\n"
          ]
        }
      ],
      "source": [
        "def get_glove_adapted_embeddings(glove_model, input_voc):\n",
        "    keys = {i: glove_model.key_to_index.get(w, None) for w, i in input_voc.items()}\n",
        "    index_dict = {i: key for i, key in keys.items() if key is not None}\n",
        "    \n",
        "    embeddings_d = glove_model.vectors.shape[1]\n",
        "    embeddings_shape = (len(input_voc),embeddings_d)\n",
        "    \n",
        "    embeddings = np.random.normal(loc=0.0,scale=0.001,size=embeddings_shape)\n",
        "    embeddings[input_voc[\"<pad>\"],:] = np.zeros((embeddings_d,))\n",
        "    embeddings[input_voc[\"<unk>\"],:] = np.zeros((embeddings_d,))\n",
        "    \n",
        "    print(embeddings.shape)\n",
        "    \n",
        "    for i, ind in index_dict.items():\n",
        "        embeddings[i] = glove_model.vectors[ind]\n",
        "    return embeddings\n",
        "\n",
        "GloveEmbeddings = get_glove_adapted_embeddings(loaded_glove_model, en_vocab.get_stoi())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B6pS-SUd0gh"
      },
      "outputs": [],
      "source": [
        "class PretrainedAveragingModel(nn.Module):\n",
        "    def __init__(self,fine_tuning=False):\n",
        "        super().__init__()\n",
        "        # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
        "        # Look into the arguments of the nn.Embedding class\n",
        "        self.embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(GloveEmbeddings))\n",
        "        self.embeddings.requires_grad = fine_tuning\n",
        "        #Â Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.linear = nn.Linear(GloveEmbeddings.shape[1],1)\n",
        "        \n",
        "        # No need for sigmoid, it will be into the criterion ! \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        #Â Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
        "        # First, take the mean of the embeddings of the document\n",
        "        x = self.embeddings(inputs)\n",
        "        x = torch.mean(x,dim=1)\n",
        "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
        "        x = self.linear(x)\n",
        "        o = torch.squeeze(x,dim=1)\n",
        "        return o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLGOC11id0gi"
      },
      "source": [
        "### Model 3: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfpx5N9Gd0gi"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, embeddings=None, fine_tuning=False):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "\n",
        "        if embeddings is None:\n",
        "            self.embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(GloveEmbeddings))\n",
        "        else:\n",
        "            self.embeddings = embeddings\n",
        "\n",
        "        self.embeddings.requires_grad = fine_tuning\n",
        "        #Â Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.linear = nn.Linear(hidden_dim,1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.embeddings(inputs)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        x = torch.squeeze(ht[-1],dim=0)\n",
        "        x = self.linear(x)\n",
        "        out = torch.squeeze(x,dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeklBKAEd0gj"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04aK7vYxd0gj",
        "outputId": "f6893010-ed70-44af-c016-d10b0640e412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55zebxYHd0gk"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, opt, criterion, dataloader,disable_bar = False):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    with tqdm(total=len(dataloader), disable=disable_bar) as pbar:\n",
        "        for i, (x, y) in enumerate(dataloader):\n",
        "            opt.zero_grad()\n",
        "            # Forward\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            # Compute the loss \n",
        "            loss = criterion(pred,y)\n",
        "            # Compute gradients with the criterion\n",
        "            loss.backward()\n",
        "            # Update weights with the optimizer\n",
        "            opt.step() \n",
        "            losses.append(loss.item())\n",
        "            \n",
        "            # Count the number of correct predictions in the batch - here, you'll need to use the sigmoid\n",
        "            num_corrects = ((pred>0) == y).sum() \n",
        "            acc = 100.0 * num_corrects/len(y)\n",
        "            accuracies.append(acc.item())\n",
        "            \n",
        "            training_loss = np.mean(losses)\n",
        "            training_accurcy = np.mean(accuracies)\n",
        "            \n",
        "            pbar.set_description(f'training loss: {training_loss:.4f}, training acc: {training_accurcy:.4f}')\n",
        "            pbar.update(1)\n",
        "            \n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGkHBzJVd0gl"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, criterion, evalloader):\n",
        "    model.eval()\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(evalloader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred,y)\n",
        "            num_corrects = ((pred>0) == y).sum() \n",
        "            acc = 100.0 * num_corrects/len(y)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "    return total_epoch_loss/(i+1), total_epoch_acc/(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO0AbaMid0gm"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping():\n",
        "    \"\"\"\n",
        "    Early stopping to stop the training when the loss does not improve after\n",
        "    certain epochs.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        \"\"\"\n",
        "        :param patience: how many epochs to wait before stopping when loss is\n",
        "               not improving\n",
        "        :param min_delta: minimum difference between new loss and old loss for\n",
        "               new loss to be considered as an improvement\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss == None:\n",
        "            self.best_loss = val_loss\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            # reset counter if validation loss improves\n",
        "            self.counter = 0\n",
        "        elif self.best_loss - val_loss < self.min_delta:\n",
        "            self.counter += 1\n",
        "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                print('INFO: Early stopping')\n",
        "                self.early_stop = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wW1rIldd0gm"
      },
      "outputs": [],
      "source": [
        "# A function which will help to execute experiments rapidly - with a early_stopping option when necessary. \n",
        "def experiment(model, opt, criterion, num_epochs = 5, use_early_stopping = True):\n",
        "    train_losses = []\n",
        "    if use_early_stopping:\n",
        "        early_stopping = EarlyStopping(patience=5,min_delta=0.01)\n",
        "        \n",
        "    print(\"Beginning training...\")\n",
        "        \n",
        "    for e in range(num_epochs):\n",
        "        print(\"Epoch \" + str(e+1) + \":\")\n",
        "            \n",
        "        train_losses += train_epoch(model, opt, criterion, training_dataloader,disable_bar=False)\n",
        "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
        "        \n",
        "        print(f'Validation loss: {valid_loss:.4f}, Validation acc: {valid_acc:.4f}')\n",
        "            \n",
        "        if use_early_stopping:\n",
        "            early_stopping(valid_loss)\n",
        "            if early_stopping.early_stop:\n",
        "                break  \n",
        "            \n",
        "    test_loss, test_acc = eval_model(model, criterion, test_dataloader)\n",
        "    print(f'Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}')\n",
        "        \n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipW_OUVqd0gn"
      },
      "source": [
        "### Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Vzx6fhd0gn"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36F-EBcid0go"
      },
      "outputs": [],
      "source": [
        "model1 = AveragingModel(300, len(en_vocab))\n",
        "model1 = model1.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model1.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "# pos_weight = torch.tensor([9]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNzJ5beTd0go",
        "outputId": "40ecfe25-1d03-48b4-937a-792314fd64b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5595, training acc: 76.4411: 100%|ââââââââââ| 203/203 [00:04<00:00, 44.15it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4462, Validation acc: 83.7385\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3572, training acc: 87.7093: 100%|ââââââââââ| 203/203 [00:01<00:00, 104.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3676, Validation acc: 87.3077\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.2697, training acc: 91.2914: 100%|ââââââââââ| 203/203 [00:02<00:00, 100.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3426, Validation acc: 88.8077\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.2180, training acc: 93.0271: 100%|ââââââââââ| 203/203 [00:02<00:00, 87.51it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3380, Validation acc: 89.4538\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1841, training acc: 94.1198: 100%|ââââââââââ| 203/203 [00:02<00:00, 94.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3495, Validation acc: 89.7077\n",
            "INFO: Early stopping counter 2 of 5\n",
            "Epoch 6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1599, training acc: 94.8223: 100%|ââââââââââ| 203/203 [00:02<00:00, 97.49it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3632, Validation acc: 89.8615\n",
            "INFO: Early stopping counter 3 of 5\n",
            "Epoch 7:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1422, training acc: 95.3782: 100%|ââââââââââ| 203/203 [00:01<00:00, 102.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3831, Validation acc: 89.6692\n",
            "INFO: Early stopping counter 4 of 5\n",
            "Epoch 8:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1283, training acc: 95.8323: 100%|ââââââââââ| 203/203 [00:01<00:00, 105.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4089, Validation acc: 89.3923\n",
            "INFO: Early stopping counter 5 of 5\n",
            "INFO: Early stopping\n",
            "Test loss: 0.3630, Test acc: 89.0462\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model1, opt, criterion,num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU8gzR3Vd0gp"
      },
      "source": [
        "#### Model2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uoefQY_d0gp"
      },
      "outputs": [],
      "source": [
        "model2 = PretrainedAveragingModel(fine_tuning=False)\n",
        "model2 = model2.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model2.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcs1q3xOd0gp",
        "outputId": "722ac207-38a5-4772-ccb3-70fea6045d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.6307, training acc: 73.7090: 100%|ââââââââââ| 203/203 [00:00<00:00, 219.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5925, Validation acc: 76.3462\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5620, training acc: 77.4636: 100%|ââââââââââ| 203/203 [00:00<00:00, 228.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5476, Validation acc: 78.9692\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5236, training acc: 79.9889: 100%|ââââââââââ| 203/203 [00:00<00:00, 218.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5193, Validation acc: 80.7846\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4979, training acc: 81.6292: 100%|ââââââââââ| 203/203 [00:00<00:00, 219.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4996, Validation acc: 81.5538\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4792, training acc: 82.3844: 100%|ââââââââââ| 203/203 [00:00<00:00, 209.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4855, Validation acc: 82.0769\n",
            "Test loss: 0.4886, Test acc: 81.2538\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model2, opt, criterion,num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fPBFMOBd0gq",
        "outputId": "ff8bd0ab-67c2-4522-fb5d-3e53cef12350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4650, training acc: 82.9738: 100%|ââââââââââ| 203/203 [00:01<00:00, 172.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4741, Validation acc: 82.3538\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4535, training acc: 83.2204: 100%|ââââââââââ| 203/203 [00:01<00:00, 159.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4661, Validation acc: 82.3231\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4445, training acc: 83.5982: 100%|ââââââââââ| 203/203 [00:01<00:00, 152.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4580, Validation acc: 82.3846\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4367, training acc: 83.7462: 100%|ââââââââââ| 203/203 [00:01<00:00, 164.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4515, Validation acc: 82.6308\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4305, training acc: 83.9046: 100%|ââââââââââ| 203/203 [00:01<00:00, 168.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4473, Validation acc: 82.7231\n",
            "Test loss: 0.4506, Test acc: 82.6385\n"
          ]
        }
      ],
      "source": [
        "model2.embeddings.requires_grad = True\n",
        "train_losses = experiment(model2, opt, criterion,num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "857cakd8d0gq"
      },
      "source": [
        "#### Model3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAuPD-dBd0gr"
      },
      "outputs": [],
      "source": [
        "model3 = LSTMModel(300,64, embeddings=model1.embeddings, fine_tuning=False)\n",
        "model3 = model3.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model3.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YTS2RjOd0gr",
        "outputId": "4e9157b5-4848-4360-8d2f-d9fcf2bdf008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5661, training acc: 67.5333: 100%|ââââââââââ| 203/203 [00:04<00:00, 41.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4767, Validation acc: 81.8385\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4177, training acc: 85.2163: 100%|ââââââââââ| 203/203 [00:04<00:00, 46.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4875, Validation acc: 79.0923\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4054, training acc: 83.8984: 100%|ââââââââââ| 203/203 [00:04<00:00, 46.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4705, Validation acc: 80.5615\n",
            "INFO: Early stopping counter 2 of 5\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3847, training acc: 85.4866: 100%|ââââââââââ| 203/203 [00:04<00:00, 46.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4688, Validation acc: 81.3615\n",
            "INFO: Early stopping counter 3 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3800, training acc: 85.8975: 100%|ââââââââââ| 203/203 [00:04<00:00, 47.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4676, Validation acc: 81.3000\n",
            "INFO: Early stopping counter 4 of 5\n",
            "Epoch 6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3732, training acc: 86.5296: 100%|ââââââââââ| 203/203 [00:04<00:00, 47.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4670, Validation acc: 81.8846\n",
            "INFO: Early stopping counter 5 of 5\n",
            "INFO: Early stopping\n",
            "Test loss: 0.4699, Test acc: 81.9308\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model3, opt, criterion,num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jndmFaMhd0gr"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCK2BTlgd0gs",
        "outputId": "17b42c54-3cf2-41cd-ead5-62c7cb1033ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (1.9.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (1.42.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (6.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: redis>=3.5.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (4.0.2)\n",
            "Requirement already satisfied: jsonschema in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (4.2.1)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (8.0.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (3.19.1)\n",
            "Requirement already satisfied: attrs in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (1.18.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from click>=7.0->ray) (0.4.4)\n",
            "Requirement already satisfied: six>=1.5.2 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from grpcio>=1.28.1->ray) (1.16.0)\n",
            "Requirement already satisfied: deprecated in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from redis>=3.5.0->ray) (1.2.13)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from jsonschema->ray) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from jsonschema->ray) (0.18.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from deprecated->redis>=3.5.0->ray) (1.13.3)\n",
            "Requirement already satisfied: tensorboardx in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from tensorboardx) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from tensorboardx) (3.19.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ray\n",
        "!pip install -U tensorboardx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVPZdeWpd0gs"
      },
      "outputs": [],
      "source": [
        "from ray import tune\n",
        "from ray.tune import JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emrlwZh8d0gt"
      },
      "outputs": [],
      "source": [
        "def train_hsr(config,checkpoint_dir=None):\n",
        "    model =  AveragingModel(config[\"d_embedding\"], len(en_vocab))\n",
        "    model = model.to(device)\n",
        "    \n",
        "    optimizer  = optim.Adam(model.parameters(), lr=config[\"lr\"], betas=(0.9, 0.999))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    training_dataloader = DataLoader(training_dataset, batch_size = int(config[\"batch_size\"]), shuffle=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size = int(config[\"batch_size\"]))\n",
        "    \n",
        "    early_stopping = EarlyStopping(patience=5,min_delta=0.01)\n",
        "    for epoch in range(20):\n",
        "        train_epoch(model, optimizer, criterion, training_dataloader,disable_bar=True)\n",
        "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
        "\n",
        "        tune.report(loss=valid_loss, accuracy=valid_acc)\n",
        "        \n",
        "        early_stopping(valid_loss)\n",
        "        if early_stopping.early_stop:\n",
        "                break  \n",
        "        \n",
        "    print(\"Finished Training\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyX6wMl_d0gt"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_search(config,num_samples=10, max_num_epochs=10):\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = JupyterNotebookReporter(\n",
        "        overwrite= True,\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    \n",
        "    result = tune.run(\n",
        "        train_hsr,\n",
        "        resources_per_trial={\"gpu\": 1},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOaRoezZd0gu"
      },
      "source": [
        "#### model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPoXcVCpd0gv"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "        \"d_embedding\" : tune.choice([64,128,256,300]),\n",
        "        \"lr\": tune.choice([0.02,0.01,0.0025]),#tune.loguniform(1e-4, 1e-3),\n",
        "        \"batch_size\": tune.choice([32,64,128])\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WHH811bd0gv",
        "outputId": "a057a188-29d8-4600-ad84-ad02bf94c8f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-12-14 20:44:37 (running for 00:07:16.51)<br>Memory usage on this node: 13.2/15.9 GiB<br>Using AsyncHyperBand: num_stopped=15\n",
              "Bracket: Iter 8.000: None | Iter 4.000: -0.3394852068561774 | Iter 2.000: -0.302070465742373 | Iter 1.000: -0.3182608139494695<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/4.82 GiB heap, 0.0/2.41 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\train_hsr_2021-12-14_20-37-20<br>Number of trials: 20/20 (20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  d_embedding</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_hsr_4103c_00000</td><td>TERMINATED</td><td>127.0.0.1:17676</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.473745</td><td style=\"text-align: right;\">   88.3578</td><td style=\"text-align: right;\">                   6</td></tr>\n",
              "<tr><td>train_hsr_4103c_00001</td><td>TERMINATED</td><td>127.0.0.1:23956</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.293922</td><td style=\"text-align: right;\">   89.4349</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00002</td><td>TERMINATED</td><td>127.0.0.1:2288 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.429869</td><td style=\"text-align: right;\">   84.2361</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00003</td><td>TERMINATED</td><td>127.0.0.1:8212 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.475382</td><td style=\"text-align: right;\">   88.2224</td><td style=\"text-align: right;\">                   6</td></tr>\n",
              "<tr><td>train_hsr_4103c_00004</td><td>TERMINATED</td><td>127.0.0.1:14436</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.422552</td><td style=\"text-align: right;\">   85.094 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00005</td><td>TERMINATED</td><td>127.0.0.1:3744 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.314119</td><td style=\"text-align: right;\">   89.006 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00006</td><td>TERMINATED</td><td>127.0.0.1:17592</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.451825</td><td style=\"text-align: right;\">   83.5664</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00007</td><td>TERMINATED</td><td>127.0.0.1:14864</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.555954</td><td style=\"text-align: right;\">   78.1671</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00008</td><td>TERMINATED</td><td>127.0.0.1:11544</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.381619</td><td style=\"text-align: right;\">   86.3583</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00009</td><td>TERMINATED</td><td>127.0.0.1:7204 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.30207 </td><td style=\"text-align: right;\">   89.2157</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00010</td><td>TERMINATED</td><td>127.0.0.1:18172</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.459787</td><td style=\"text-align: right;\">   82.63  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00011</td><td>TERMINATED</td><td>127.0.0.1:15584</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.365432</td><td style=\"text-align: right;\">   89.3689</td><td style=\"text-align: right;\">                   7</td></tr>\n",
              "<tr><td>train_hsr_4103c_00012</td><td>TERMINATED</td><td>127.0.0.1:9560 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.44245 </td><td style=\"text-align: right;\">   88.8869</td><td style=\"text-align: right;\">                   7</td></tr>\n",
              "<tr><td>train_hsr_4103c_00013</td><td>TERMINATED</td><td>127.0.0.1:2996 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.300252</td><td style=\"text-align: right;\">   90.0735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00014</td><td>TERMINATED</td><td>127.0.0.1:18448</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.316217</td><td style=\"text-align: right;\">   89.1108</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00015</td><td>TERMINATED</td><td>127.0.0.1:9824 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.426858</td><td style=\"text-align: right;\">   89.0972</td><td style=\"text-align: right;\">                   7</td></tr>\n",
              "<tr><td>train_hsr_4103c_00016</td><td>TERMINATED</td><td>127.0.0.1:7100 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.307833</td><td style=\"text-align: right;\">   89.7029</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00017</td><td>TERMINATED</td><td>127.0.0.1:12992</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.306959</td><td style=\"text-align: right;\">   89.4608</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00018</td><td>TERMINATED</td><td>127.0.0.1:21596</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.304777</td><td style=\"text-align: right;\">   89.4608</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00019</td><td>TERMINATED</td><td>127.0.0.1:2008 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.438319</td><td style=\"text-align: right;\">   85.2143</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-14 20:44:37,504\tINFO tune.py:626 -- Total run time: 437.31 seconds (436.49 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial config: {'d_embedding': 256, 'lr': 0.01, 'batch_size': 64}\n",
            "Best trial final validation loss: 0.2939215717362423\n",
            "Best trial final validation accuracy: 89.43491288727405\n"
          ]
        }
      ],
      "source": [
        "hyperparameter_search(config,num_samples=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocMC6wv1d0gw"
      },
      "source": [
        "### Best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUSYmza6d0gw"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "## Dataloaders\n",
        "training_dataloader = DataLoader(training_dataset, batch_size = BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plYfpmvyd0gx"
      },
      "outputs": [],
      "source": [
        "model1 = AveragingModel(256, len(en_vocab))\n",
        "model1 = model1.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model1.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "# pos_weight = torch.tensor([9]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld4VGny8d0gx",
        "outputId": "ec76b202-1680-4d08-bac6-aa60d747209b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0955, training acc: 96.6302: 100%|ââââââââââ| 406/406 [00:04<00:00, 98.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5103, Validation acc: 87.8769\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0892, training acc: 96.8065: 100%|ââââââââââ| 406/406 [00:04<00:00, 96.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5636, Validation acc: 87.9385\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0811, training acc: 97.0312: 100%|ââââââââââ| 406/406 [00:04<00:00, 95.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5959, Validation acc: 87.5077\n",
            "INFO: Early stopping counter 2 of 5\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0774, training acc: 97.2421: 100%|ââââââââââ| 406/406 [00:04<00:00, 87.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6431, Validation acc: 87.8154\n",
            "INFO: Early stopping counter 3 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0724, training acc: 97.3738: 100%|ââââââââââ| 406/406 [00:04<00:00, 91.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6892, Validation acc: 87.7538\n",
            "INFO: Early stopping counter 4 of 5\n",
            "Epoch 6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0694, training acc: 97.5754: 100%|ââââââââââ| 406/406 [00:04<00:00, 92.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.7322, Validation acc: 87.3538\n",
            "INFO: Early stopping counter 5 of 5\n",
            "INFO: Early stopping\n",
            "Test loss: 0.7870, Test acc: 88.2000\n"
          ]
        }
      ],
      "source": [
        "losses = experiment(model1, opt, criterion,num_epochs=20,use_early_stopping=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEXYTaUVd0gy"
      },
      "source": [
        "## Inspect model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxFXjJxnd0gy"
      },
      "outputs": [],
      "source": [
        "def hate_speech_recognition(text,model):\n",
        "    text_dataset = TextClassificationDataset([text],[0],en_vocab)\n",
        "    text_dataloader = DataLoader(text_dataset, batch_size = 1)\n",
        "    x,y = next(iter(text_dataloader))\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(x)\n",
        "        ## less than 0 -> non hate (class 0)\n",
        "        ## else Hate -> (class 1)\n",
        "        ## since there is no sigmoid acivation in the last layer \n",
        "        text_class = (pred>0)\n",
        "    result = text_class[0].item()\n",
        "    \n",
        "    ## print results\n",
        "    if result:\n",
        "        print(\"hate speech detected\")\n",
        "    else:\n",
        "        print(\"non hate speech\")\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWDEuEBHd0gz"
      },
      "outputs": [],
      "source": [
        "model1 = model1.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5mjFN7qd0gz",
        "outputId": "fda6b761-a778-408d-d7d2-5b1450120cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hate speech detected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hate_speech_recognition(\"I hate you\",model=model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9ZMw4tad0g0"
      },
      "outputs": [],
      "source": [
        "def inspect_model(model, evalloader):\n",
        "    model.eval()\n",
        "    false_positive = []\n",
        "    false_negative = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(evalloader):\n",
        "            pred = model(x)\n",
        "            text_class = (pred>0)\n",
        "            \n",
        "            if text_class != y:\n",
        "                result = text_class[0].item()\n",
        "                if result:\n",
        "                    false_positive.append(i)\n",
        "                else:\n",
        "                    false_negative.append(i)\n",
        "    return false_positive,false_negative\n",
        "\n",
        "\n",
        "inspect_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
        "false_positive,false_negative = inspect_model(model1,inspect_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9jCwvuSd0g0",
        "outputId": "b10208d6-7b41-4ab1-a59c-236368a90f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "179\n"
          ]
        }
      ],
      "source": [
        "print(len(false_positive))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IopQ-H1d0g1"
      },
      "source": [
        "### False Hate (false Positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaO8H8h3d0g1",
        "outputId": "37bd7bbb-de14-458e-a82b-269e50b0aa23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hate speech detected\n",
            "PLAIN text:\n",
            "Ombudsman\n",
            "\n",
            "is there for for Wiki?\n",
            "\n",
            "beckjord\n",
            "\n",
            "TOKENIZED TEXT:\n",
            "['ombudsman', 'wiki', 'beckjord']\n",
            "\n",
            "Predicted:  Hate\n",
            "True Label:  Non hate\n",
            "hate speech detected\n",
            "PLAIN text:\n",
            "Thanks! ) \n",
            "\n",
            "Hi, just wanted to let you know that I think you're a total loser to be patrolling recent changes.  Go outside and do us all a favor.\n",
            "Note: you ARE being reported for vandalism  stop it.\n",
            "\n",
            "TOKENIZED TEXT:\n",
            "['thank', 'want', 'let', 'know', 'think', 'total', 'loser', 'patrol', 'recent', 'chang', 'outsid', 'favor', 'note', 'report', 'vandal', 'stop']\n",
            "\n",
            "Predicted:  Hate\n",
            "True Label:  Non hate\n"
          ]
        }
      ],
      "source": [
        "## false Positive\n",
        "for i in false_positive[14:16]:\n",
        "    text = test_x.iloc[i]\n",
        "    pred_label = hate_speech_recognition(text,model=model1)\n",
        "    true_label = test_y.iloc[i]\n",
        "    print(\"PLAIN text:\")\n",
        "    print(text)\n",
        "    print()\n",
        "    print(\"TOKENIZED TEXT:\")\n",
        "    print(clean_and_tokenize(text))\n",
        "    print()\n",
        "    print(\"Predicted: \",\"Hate\" if pred_label else \"Non hate\")\n",
        "    print(\"True Label: \",\"Hate\" if true_label==1 else \"Non hate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CZBAh6zd0g2"
      },
      "source": [
        "### False Non Hate (false Negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ0Gc4Ond0g2",
        "outputId": "b3ec003c-31d4-44ad-b838-bb781428f645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "non hate speech\n",
            "PLAIN text:\n",
            "Definition of fat- Lauren Lozano!\n",
            "\n",
            "TOKENIZED TEXT:\n",
            "['definit', 'fat', 'lauren', 'lozano']\n",
            "\n",
            "Predicted:  Non hate\n",
            "True Label:  Hate\n"
          ]
        }
      ],
      "source": [
        "## false Negative\n",
        "for i in false_negative[32:33]:\n",
        "    text = test_x.iloc[i]\n",
        "    pred_label = hate_speech_recognition(text,model=model1)\n",
        "    true_label = test_y.iloc[i]\n",
        "    print(\"PLAIN text:\")\n",
        "    print(text)\n",
        "    print()\n",
        "    print(\"TOKENIZED TEXT:\")\n",
        "    print(clean_and_tokenize(text))\n",
        "    print()\n",
        "    print(\"Predicted: \",\"Hate\" if pred_label else \"Non hate\")\n",
        "    print(\"True Label: \",\"Hate\" if true_label==1 else \"Non hate\")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9b432319b1b054266bcdf59eb764237d3d3272012fbf9a2e21780dc801e4d991"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('tf': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}