{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthagrowl/Offensive-Hate-Speech-Detection/blob/main/offensive_speech_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exg_V5Bvd0f6"
      },
      "source": [
        "# Offensive/Hate Speech Detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxcku2kvd0f9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBkLwoENd0gC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YW-Jprad0gD"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X3CG0bHd0gE"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('dataset.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt1DtloXd0gF",
        "outputId": "3a6f6744-7ac8-4c25-a34d-231c3dd6192d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>hate_speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  hate_speech\n",
              "0  Explanation\\nWhy the edits made under my usern...            0\n",
              "1  D'aww! He matches this background colour I'm s...            0\n",
              "2  Hey man, I'm really not trying to edit war. It...            0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...            0\n",
              "4  You, sir, are my hero. Any chance you remember...            0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArE4j00qd0gH",
        "outputId": "a83907dc-004a-450a-9e4a-a5e4f5c83a6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(159571, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQxgWpgd0gI",
        "outputId": "39ffcbda-577f-4a85-f7fc-bfe32b9e092c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count   Dtype \n",
            "---  ------       --------------   ----- \n",
            " 0   comment      159571 non-null  object\n",
            " 1   hate_speech  159571 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQoEB_xgd0gI",
        "outputId": "b10c73d9-257f-4474-dac9-bc29c376fda8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "comment        0.0\n",
              "hate_speech    0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check the percentage of nan values \n",
        "data.isna().sum() / len(data) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA9lmzQ2d0gJ"
      },
      "source": [
        "### Visualisation and Distrubution of the speech\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGbBEHxyd0gK",
        "outputId": "c8478e30-4eb2-426b-979e-d457458018c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='hate_speech', ylabel='count'>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize = (8,4))\n",
        "sns.countplot(x = data[\"hate_speech\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwNkq3O-d0gL",
        "outputId": "ee2df8fb-b11d-47e4-c6e3-3c77d9e4d1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class 0 (non hate speech): 89.83%\n",
            "class 1 (hate speech): 10.17%\n"
          ]
        }
      ],
      "source": [
        "print(f'class 0 (non hate speech): {np.sum(data[\"hate_speech\"] == 0) / len(data) *100:.2f}%')\n",
        "print(f'class 1 (hate speech): {np.sum(data[\"hate_speech\"] == 1) / len(data) *100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtE9u8eWd0gM"
      },
      "source": [
        "### Undersampling the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QewWi3Vd0gM"
      },
      "outputs": [],
      "source": [
        "hate_data = data.loc[data.hate_speech == 1]\n",
        "non_hate_data = data.loc[data.hate_speech == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ4Uj6v2d0gN"
      },
      "outputs": [],
      "source": [
        "balanced_non_hate_data = data.loc[np.random.choice(non_hate_data.index, len(hate_data))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYubdoRZd0gO"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([balanced_non_hate_data,hate_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdZDNwRbd0gP",
        "outputId": "6aa6a4ac-6dad-4fd8-c841-43209ab140b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='hate_speech', ylabel='count'>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize = (8,4))\n",
        "sns.countplot(x = df[\"hate_speech\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeYLbN7Yd0gQ",
        "outputId": "a5bf454d-7d25-4c7c-ca72-fe72aef68478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class 0 (non hate speech): 50.00%\n",
            "class 1 (hate speech): 50.00%\n"
          ]
        }
      ],
      "source": [
        "print(f'class 0 (non hate speech): {np.sum(df[\"hate_speech\"] == 0) / len(df) *100:.2f}%')\n",
        "print(f'class 1 (hate speech): {np.sum(df[\"hate_speech\"] == 1) / len(df) *100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQgdHiR_d0gR"
      },
      "source": [
        "### Data preparation: train-val-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzjsQtXEd0gR"
      },
      "outputs": [],
      "source": [
        "def get_splits(x, y, splits):\n",
        "    \"\"\"\n",
        "    The idea is to use an index list as reference:\n",
        "    To shuffle it randomly:\n",
        "    We need 'splits' to contain 2 values. \n",
        "  \n",
        "    \"\"\"\n",
        "    # Create an index list and shuffle it - use the function random.shuffle\n",
        "    data_len = len(x)\n",
        "    index_list = np.arange(data_len)\n",
        "    np.random.shuffle(index_list)\n",
        "    # Find the two indexes we'll use to cut the lists from the splits\n",
        "    train_cut_index = int(data_len*splits[0])\n",
        "    valid_cut_index = int(data_len*(splits[0]+splits[1]))\n",
        "    # Do the cutting (careful: you can't use a list as index for a list - this only works with tensors)\n",
        "    # (you need to use list comprehensions - or go through numpy)\n",
        "    train_x, train_y = np.take(x,index_list[:train_cut_index]),np.take(y,index_list[:train_cut_index])\n",
        "    valid_x, valid_y = np.take(x,index_list[train_cut_index:valid_cut_index]),np.take(y,index_list[train_cut_index:valid_cut_index])\n",
        "    test_x, test_y = np.take(x,index_list[valid_cut_index:]),np.take(y,index_list[valid_cut_index:])\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy5kDt_vd0gT"
      },
      "outputs": [],
      "source": [
        "# Choose the training, validation, testing splits\n",
        "splits = (0.8, 0.1)\n",
        "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = get_splits(df.comment, df.hate_speech, splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjUXQBtzd0gT"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wrv9Oqad0gU",
        "outputId": "40e1c9bb-271c-49c1-ad3e-cafa54d7d627"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWrkIG4Hd0gV"
      },
      "outputs": [],
      "source": [
        "def clean_and_tokenize(text):\n",
        "    \"\"\"  \n",
        "    Process text function.\n",
        "    Input: text\n",
        "    Output: text_clean: a list of words containing the processed text \n",
        "    \n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "    # remove hyperlinks    \n",
        "    text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n",
        "    # only removing the hash # sign from the word\n",
        "    text = re.sub(r'#', '', text)\n",
        "    # remove numbers, points, \n",
        "    text = re.sub(r'[0-9]+', '',text)\n",
        "    text = re.sub(r'\\.', '', text)\n",
        "    # Remove small words (1 and 2 characters)\n",
        "    text = re.sub(r\"\\b\\w{1,2}\\b\", \"\", text)    \n",
        "    text = text.lower()\n",
        "    # tokenize text\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    text_tokens = tokenizer.tokenize(text)\n",
        "    text_clean = []\n",
        "    \n",
        "    for word in text_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            text_clean.append(stem_word)\n",
        "\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPHvVZH5d0gX",
        "outputId": "0557fd84-4a84-4f71-bc75-11ed7cdd5515"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['love', 'machin', 'learn', 'nchsd', ':)']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_and_tokenize(\"I love machine learning 0 */nchsd<p> :)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogwu-N5Yd0gY"
      },
      "outputs": [],
      "source": [
        "text_len = [len(clean_and_tokenize(s)) for s in df.comment]\n",
        "text_len = [l for l in text_len if l <500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFQ8gQYvd0gY",
        "outputId": "acdcc530-8d77-4644-961c-d8c11dfe6eea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(data=text_len,bins=50)\n",
        "plt.title(\"sentence length distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GgrpSdjd0gZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2R9EH6Jd0gZ"
      },
      "source": [
        "#### Creating the Vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp-gusdWd0gZ"
      },
      "outputs": [],
      "source": [
        "def build_vocab(df, tokenizer,min_freq = 1):\n",
        "    assert min_freq > 0\n",
        "    counter = Counter(['<unk>', '<pad>']*min_freq)\n",
        "    for s in df:\n",
        "        counter.update(tokenizer(s))\n",
        "    v =  vocab(counter,min_freq=min_freq)\n",
        "    unk_token = '<unk>'\n",
        "    v.set_default_index(v[unk_token])\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21dpnwXpd0ga"
      },
      "outputs": [],
      "source": [
        "en_vocab = build_vocab(df.comment,clean_and_tokenize,min_freq=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4x-XpB1d0ga",
        "outputId": "15d25673-b985-41f2-b6ee-09bccc99cc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10863\n"
          ]
        }
      ],
      "source": [
        "print(len(en_vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5IyUV1nd0gb"
      },
      "outputs": [],
      "source": [
        "PAD_IDX = en_vocab['<pad>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN7cd1WHd0gb"
      },
      "source": [
        "#### Pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTVe1y2Rd0gc"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data, categories, vocab = None, max_length = 100,min_freq = 5):\n",
        "        # Text data\n",
        "        self.data = data\n",
        "        \n",
        "        # Allow to import a vocabulary (for valid/test datasets, that will use the training vocabulary)\n",
        "        if vocab is not None:\n",
        "            self.vocab = vocab\n",
        "        else:\n",
        "            # If no vocabulary imported, build it\n",
        "            self.vocab = build_vocab(self.data, clean_and_tokenize,min_freq)\n",
        "\n",
        "        # Tokenize the data\n",
        "        # Transform words into lists of indexes\n",
        "        # Transform this list of of indexes into Pytorch Tensor\n",
        "        tensor_data = [ torch.tensor([vocab[w] for w in clean_and_tokenize(sentence)][:max_length]) for sentence in self.data ]\n",
        "        self.tensor_data = pad_sequence(tensor_data, batch_first=True, padding_value = PAD_IDX)\n",
        "        \n",
        "        \n",
        "        # Transform the categories into a FloatTensor\n",
        "        self.tensor_y  = torch.FloatTensor(np.array(categories))\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # The iterator just gets one particular example with its category\n",
        "        # The dataloader will take care of the shuffling and batching\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        return self.tensor_data[idx], self.tensor_y[idx] \n",
        "    \n",
        "    def get_vocab(self):\n",
        "        # A simple way to get the training vocab when building the valid/test \n",
        "        return self.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2jX-Lf4d0gc"
      },
      "outputs": [],
      "source": [
        "training_dataset = TextClassificationDataset(train_x, train_y,en_vocab)\n",
        "valid_dataset = TextClassificationDataset(valid_x, valid_y, en_vocab)\n",
        "test_dataset = TextClassificationDataset(test_x, test_y,en_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c29cN-2Nd0gd"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "## Dataloaders\n",
        "training_dataloader = DataLoader(training_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = 25)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3-crj_hd0ge"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIfPURKad0ge"
      },
      "source": [
        "### Model 1 : Simple averaging model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL-QNWDad0gf"
      },
      "outputs": [],
      "source": [
        "class AveragingModel(nn.Module):    \n",
        "    def __init__(self, embedding_dim, vocabulary_size):\n",
        "        super().__init__()\n",
        "        # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
        "        # Look into the arguments of the nn.Embedding class\n",
        "        self.embeddings = nn.Embedding(vocabulary_size,embedding_dim=embedding_dim,padding_idx= PAD_IDX)\n",
        "        # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.fc1 = nn.Linear(embedding_dim,1)\n",
        "        \n",
        "        # No need for sigmoid, it will be into the criterion ! \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        # Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
        "        # First, take the mean of the embeddings of the document\n",
        "        x = self.embeddings(inputs)\n",
        "        x = torch.mean(x,dim=1)\n",
        "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
        "        x = self.fc1(x)\n",
        "        o = torch.squeeze(x,dim=1)\n",
        "        return o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_zolsatd0gf"
      },
      "source": [
        "### Model 2: Pretrained Averaging Model with Glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IsSAWPid0gg",
        "outputId": "2c9cff72-cc21-4612-d23b-6c86b6c5dc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (4.1.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: Cython==0.29.23 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (0.29.23)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from gensim) (1.18.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqUSDg8Td0gg"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "loaded_glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
        "loaded_glove_embeddings = loaded_glove_model.vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWtK2PoEd0gh",
        "outputId": "77b5edf0-f5ab-472d-ceaa-79ab849002af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10863, 300)\n"
          ]
        }
      ],
      "source": [
        "def get_glove_adapted_embeddings(glove_model, input_voc):\n",
        "    keys = {i: glove_model.key_to_index.get(w, None) for w, i in input_voc.items()}\n",
        "    index_dict = {i: key for i, key in keys.items() if key is not None}\n",
        "    \n",
        "    embeddings_d = glove_model.vectors.shape[1]\n",
        "    embeddings_shape = (len(input_voc),embeddings_d)\n",
        "    \n",
        "    embeddings = np.random.normal(loc=0.0,scale=0.001,size=embeddings_shape)\n",
        "    embeddings[input_voc[\"<pad>\"],:] = np.zeros((embeddings_d,))\n",
        "    embeddings[input_voc[\"<unk>\"],:] = np.zeros((embeddings_d,))\n",
        "    \n",
        "    print(embeddings.shape)\n",
        "    \n",
        "    for i, ind in index_dict.items():\n",
        "        embeddings[i] = glove_model.vectors[ind]\n",
        "    return embeddings\n",
        "\n",
        "GloveEmbeddings = get_glove_adapted_embeddings(loaded_glove_model, en_vocab.get_stoi())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B6pS-SUd0gh"
      },
      "outputs": [],
      "source": [
        "class PretrainedAveragingModel(nn.Module):\n",
        "    def __init__(self,fine_tuning=False):\n",
        "        super().__init__()\n",
        "        # Create an embedding object. Be careful to padding - you need to increase the vocabulary size by one !\n",
        "        # Look into the arguments of the nn.Embedding class\n",
        "        self.embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(GloveEmbeddings))\n",
        "        self.embeddings.requires_grad = fine_tuning\n",
        "        # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.linear = nn.Linear(GloveEmbeddings.shape[1],1)\n",
        "        \n",
        "        # No need for sigmoid, it will be into the criterion ! \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        # Remember: the inpts are written as Batch_size * seq_length * embedding_dim\n",
        "        # First, take the mean of the embeddings of the document\n",
        "        x = self.embeddings(inputs)\n",
        "        x = torch.mean(x,dim=1)\n",
        "        # Then make it go through the linear layer and remove the extra dimension with the method .squeeze()\n",
        "        x = self.linear(x)\n",
        "        o = torch.squeeze(x,dim=1)\n",
        "        return o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLGOC11id0gi"
      },
      "source": [
        "### Model 3: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfpx5N9Gd0gi"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, embeddings=None, fine_tuning=False):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
        "\n",
        "        if embeddings is None:\n",
        "            self.embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(GloveEmbeddings))\n",
        "        else:\n",
        "            self.embeddings = embeddings\n",
        "\n",
        "        self.embeddings.requires_grad = fine_tuning\n",
        "        # Create a linear layer that will transform the mean of the embeddings into a classification score\n",
        "        self.linear = nn.Linear(hidden_dim,1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.embeddings(inputs)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        x = torch.squeeze(ht[-1],dim=0)\n",
        "        x = self.linear(x)\n",
        "        out = torch.squeeze(x,dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeklBKAEd0gj"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04aK7vYxd0gj",
        "outputId": "f6893010-ed70-44af-c016-d10b0640e412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55zebxYHd0gk"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, opt, criterion, dataloader,disable_bar = False):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    with tqdm(total=len(dataloader), disable=disable_bar) as pbar:\n",
        "        for i, (x, y) in enumerate(dataloader):\n",
        "            opt.zero_grad()\n",
        "            # Forward\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            # Compute the loss \n",
        "            loss = criterion(pred,y)\n",
        "            # Compute gradients with the criterion\n",
        "            loss.backward()\n",
        "            # Update weights with the optimizer\n",
        "            opt.step() \n",
        "            losses.append(loss.item())\n",
        "            \n",
        "            # Count the number of correct predictions in the batch - here, you'll need to use the sigmoid\n",
        "            num_corrects = ((pred>0) == y).sum() \n",
        "            acc = 100.0 * num_corrects/len(y)\n",
        "            accuracies.append(acc.item())\n",
        "            \n",
        "            training_loss = np.mean(losses)\n",
        "            training_accurcy = np.mean(accuracies)\n",
        "            \n",
        "            pbar.set_description(f'training loss: {training_loss:.4f}, training acc: {training_accurcy:.4f}')\n",
        "            pbar.update(1)\n",
        "            \n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGkHBzJVd0gl"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, criterion, evalloader):\n",
        "    model.eval()\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(evalloader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred,y)\n",
        "            num_corrects = ((pred>0) == y).sum() \n",
        "            acc = 100.0 * num_corrects/len(y)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "    return total_epoch_loss/(i+1), total_epoch_acc/(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO0AbaMid0gm"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping():\n",
        "    \"\"\"\n",
        "    Early stopping to stop the training when the loss does not improve after\n",
        "    certain epochs.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        \"\"\"\n",
        "        :param patience: how many epochs to wait before stopping when loss is\n",
        "               not improving\n",
        "        :param min_delta: minimum difference between new loss and old loss for\n",
        "               new loss to be considered as an improvement\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss == None:\n",
        "            self.best_loss = val_loss\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            # reset counter if validation loss improves\n",
        "            self.counter = 0\n",
        "        elif self.best_loss - val_loss < self.min_delta:\n",
        "            self.counter += 1\n",
        "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                print('INFO: Early stopping')\n",
        "                self.early_stop = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wW1rIldd0gm"
      },
      "outputs": [],
      "source": [
        "# A function which will help to execute experiments rapidly - with a early_stopping option when necessary. \n",
        "def experiment(model, opt, criterion, num_epochs = 5, use_early_stopping = True):\n",
        "    train_losses = []\n",
        "    if use_early_stopping:\n",
        "        early_stopping = EarlyStopping(patience=5,min_delta=0.01)\n",
        "        \n",
        "    print(\"Beginning training...\")\n",
        "        \n",
        "    for e in range(num_epochs):\n",
        "        print(\"Epoch \" + str(e+1) + \":\")\n",
        "            \n",
        "        train_losses += train_epoch(model, opt, criterion, training_dataloader,disable_bar=False)\n",
        "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
        "        \n",
        "        print(f'Validation loss: {valid_loss:.4f}, Validation acc: {valid_acc:.4f}')\n",
        "            \n",
        "        if use_early_stopping:\n",
        "            early_stopping(valid_loss)\n",
        "            if early_stopping.early_stop:\n",
        "                break  \n",
        "            \n",
        "    test_loss, test_acc = eval_model(model, criterion, test_dataloader)\n",
        "    print(f'Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}')\n",
        "        \n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipW_OUVqd0gn"
      },
      "source": [
        "### Model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Vzx6fhd0gn"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36F-EBcid0go"
      },
      "outputs": [],
      "source": [
        "model1 = AveragingModel(300, len(en_vocab))\n",
        "model1 = model1.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model1.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "# pos_weight = torch.tensor([9]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNzJ5beTd0go",
        "outputId": "40ecfe25-1d03-48b4-937a-792314fd64b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5595, training acc: 76.4411: 100%|██████████| 203/203 [00:04<00:00, 44.15it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4462, Validation acc: 83.7385\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3572, training acc: 87.7093: 100%|██████████| 203/203 [00:01<00:00, 104.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3676, Validation acc: 87.3077\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.2697, training acc: 91.2914: 100%|██████████| 203/203 [00:02<00:00, 100.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3426, Validation acc: 88.8077\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.2180, training acc: 93.0271: 100%|██████████| 203/203 [00:02<00:00, 87.51it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3380, Validation acc: 89.4538\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1841, training acc: 94.1198: 100%|██████████| 203/203 [00:02<00:00, 94.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3495, Validation acc: 89.7077\n",
            "INFO: Early stopping counter 2 of 5\n",
            "Epoch 6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1599, training acc: 94.8223: 100%|██████████| 203/203 [00:02<00:00, 97.49it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3632, Validation acc: 89.8615\n",
            "INFO: Early stopping counter 3 of 5\n",
            "Epoch 7:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1422, training acc: 95.3782: 100%|██████████| 203/203 [00:01<00:00, 102.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3831, Validation acc: 89.6692\n",
            "INFO: Early stopping counter 4 of 5\n",
            "Epoch 8:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.1283, training acc: 95.8323: 100%|██████████| 203/203 [00:01<00:00, 105.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4089, Validation acc: 89.3923\n",
            "INFO: Early stopping counter 5 of 5\n",
            "INFO: Early stopping\n",
            "Test loss: 0.3630, Test acc: 89.0462\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model1, opt, criterion,num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU8gzR3Vd0gp"
      },
      "source": [
        "#### Model2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uoefQY_d0gp"
      },
      "outputs": [],
      "source": [
        "model2 = PretrainedAveragingModel(fine_tuning=False)\n",
        "model2 = model2.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model2.parameters(), lr=0.0025, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcs1q3xOd0gp",
        "outputId": "722ac207-38a5-4772-ccb3-70fea6045d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.6307, training acc: 73.7090: 100%|██████████| 203/203 [00:00<00:00, 219.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5925, Validation acc: 76.3462\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5620, training acc: 77.4636: 100%|██████████| 203/203 [00:00<00:00, 228.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5476, Validation acc: 78.9692\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5236, training acc: 79.9889: 100%|██████████| 203/203 [00:00<00:00, 218.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5193, Validation acc: 80.7846\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4979, training acc: 81.6292: 100%|██████████| 203/203 [00:00<00:00, 219.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4996, Validation acc: 81.5538\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4792, training acc: 82.3844: 100%|██████████| 203/203 [00:00<00:00, 209.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4855, Validation acc: 82.0769\n",
            "Test loss: 0.4886, Test acc: 81.2538\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model2, opt, criterion,num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fPBFMOBd0gq",
        "outputId": "ff8bd0ab-67c2-4522-fb5d-3e53cef12350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4650, training acc: 82.9738: 100%|██████████| 203/203 [00:01<00:00, 172.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4741, Validation acc: 82.3538\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4535, training acc: 83.2204: 100%|██████████| 203/203 [00:01<00:00, 159.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4661, Validation acc: 82.3231\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4445, training acc: 83.5982: 100%|██████████| 203/203 [00:01<00:00, 152.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4580, Validation acc: 82.3846\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4367, training acc: 83.7462: 100%|██████████| 203/203 [00:01<00:00, 164.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4515, Validation acc: 82.6308\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4305, training acc: 83.9046: 100%|██████████| 203/203 [00:01<00:00, 168.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4473, Validation acc: 82.7231\n",
            "Test loss: 0.4506, Test acc: 82.6385\n"
          ]
        }
      ],
      "source": [
        "model2.embeddings.requires_grad = True\n",
        "train_losses = experiment(model2, opt, criterion,num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "857cakd8d0gq"
      },
      "source": [
        "#### Model3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAuPD-dBd0gr"
      },
      "outputs": [],
      "source": [
        "model3 = LSTMModel(300,64, embeddings=model1.embeddings, fine_tuning=False)\n",
        "model3 = model3.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model3.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YTS2RjOd0gr",
        "outputId": "4e9157b5-4848-4360-8d2f-d9fcf2bdf008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.5661, training acc: 67.5333: 100%|██████████| 203/203 [00:04<00:00, 41.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4767, Validation acc: 81.8385\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4177, training acc: 85.2163: 100%|██████████| 203/203 [00:04<00:00, 46.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4875, Validation acc: 79.0923\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.4054, training acc: 83.8984: 100%|██████████| 203/203 [00:04<00:00, 46.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4705, Validation acc: 80.5615\n",
            "INFO: Early stopping counter 2 of 5\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3847, training acc: 85.4866: 100%|██████████| 203/203 [00:04<00:00, 46.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4688, Validation acc: 81.3615\n",
            "INFO: Early stopping counter 3 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3800, training acc: 85.8975: 100%|██████████| 203/203 [00:04<00:00, 47.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4676, Validation acc: 81.3000\n",
            "INFO: Early stopping counter 4 of 5\n",
            "Epoch 6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.3732, training acc: 86.5296: 100%|██████████| 203/203 [00:04<00:00, 47.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4670, Validation acc: 81.8846\n",
            "INFO: Early stopping counter 5 of 5\n",
            "INFO: Early stopping\n",
            "Test loss: 0.4699, Test acc: 81.9308\n"
          ]
        }
      ],
      "source": [
        "train_losses = experiment(model3, opt, criterion,num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jndmFaMhd0gr"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCK2BTlgd0gs",
        "outputId": "17b42c54-3cf2-41cd-ead5-62c7cb1033ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (1.9.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (1.42.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (6.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: redis>=3.5.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (4.0.2)\n",
            "Requirement already satisfied: jsonschema in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (4.2.1)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (8.0.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (3.19.1)\n",
            "Requirement already satisfied: attrs in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from ray) (1.18.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from click>=7.0->ray) (0.4.4)\n",
            "Requirement already satisfied: six>=1.5.2 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from grpcio>=1.28.1->ray) (1.16.0)\n",
            "Requirement already satisfied: deprecated in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from redis>=3.5.0->ray) (1.2.13)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from jsonschema->ray) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from jsonschema->ray) (0.18.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from deprecated->redis>=3.5.0->ray) (1.13.3)\n",
            "Requirement already satisfied: tensorboardx in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from tensorboardx) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\user\\anaconda3\\envs\\kite\\lib\\site-packages (from tensorboardx) (3.19.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ray\n",
        "!pip install -U tensorboardx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVPZdeWpd0gs"
      },
      "outputs": [],
      "source": [
        "from ray import tune\n",
        "from ray.tune import JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emrlwZh8d0gt"
      },
      "outputs": [],
      "source": [
        "def train_hsr(config,checkpoint_dir=None):\n",
        "    model =  AveragingModel(config[\"d_embedding\"], len(en_vocab))\n",
        "    model = model.to(device)\n",
        "    \n",
        "    optimizer  = optim.Adam(model.parameters(), lr=config[\"lr\"], betas=(0.9, 0.999))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    training_dataloader = DataLoader(training_dataset, batch_size = int(config[\"batch_size\"]), shuffle=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size = int(config[\"batch_size\"]))\n",
        "    \n",
        "    early_stopping = EarlyStopping(patience=5,min_delta=0.01)\n",
        "    for epoch in range(20):\n",
        "        train_epoch(model, optimizer, criterion, training_dataloader,disable_bar=True)\n",
        "        valid_loss, valid_acc = eval_model(model, criterion, valid_dataloader)\n",
        "\n",
        "        tune.report(loss=valid_loss, accuracy=valid_acc)\n",
        "        \n",
        "        early_stopping(valid_loss)\n",
        "        if early_stopping.early_stop:\n",
        "                break  \n",
        "        \n",
        "    print(\"Finished Training\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyX6wMl_d0gt"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_search(config,num_samples=10, max_num_epochs=10):\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = JupyterNotebookReporter(\n",
        "        overwrite= True,\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    \n",
        "    result = tune.run(\n",
        "        train_hsr,\n",
        "        resources_per_trial={\"gpu\": 1},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOaRoezZd0gu"
      },
      "source": [
        "#### model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPoXcVCpd0gv"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "        \"d_embedding\" : tune.choice([64,128,256,300]),\n",
        "        \"lr\": tune.choice([0.02,0.01,0.0025]),#tune.loguniform(1e-4, 1e-3),\n",
        "        \"batch_size\": tune.choice([32,64,128])\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WHH811bd0gv",
        "outputId": "a057a188-29d8-4600-ad84-ad02bf94c8f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-12-14 20:44:37 (running for 00:07:16.51)<br>Memory usage on this node: 13.2/15.9 GiB<br>Using AsyncHyperBand: num_stopped=15\n",
              "Bracket: Iter 8.000: None | Iter 4.000: -0.3394852068561774 | Iter 2.000: -0.302070465742373 | Iter 1.000: -0.3182608139494695<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/4.82 GiB heap, 0.0/2.41 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\train_hsr_2021-12-14_20-37-20<br>Number of trials: 20/20 (20 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name           </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  d_embedding</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_hsr_4103c_00000</td><td>TERMINATED</td><td>127.0.0.1:17676</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.473745</td><td style=\"text-align: right;\">   88.3578</td><td style=\"text-align: right;\">                   6</td></tr>\n",
              "<tr><td>train_hsr_4103c_00001</td><td>TERMINATED</td><td>127.0.0.1:23956</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.293922</td><td style=\"text-align: right;\">   89.4349</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00002</td><td>TERMINATED</td><td>127.0.0.1:2288 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.429869</td><td style=\"text-align: right;\">   84.2361</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00003</td><td>TERMINATED</td><td>127.0.0.1:8212 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.475382</td><td style=\"text-align: right;\">   88.2224</td><td style=\"text-align: right;\">                   6</td></tr>\n",
              "<tr><td>train_hsr_4103c_00004</td><td>TERMINATED</td><td>127.0.0.1:14436</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.422552</td><td style=\"text-align: right;\">   85.094 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00005</td><td>TERMINATED</td><td>127.0.0.1:3744 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.314119</td><td style=\"text-align: right;\">   89.006 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00006</td><td>TERMINATED</td><td>127.0.0.1:17592</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.451825</td><td style=\"text-align: right;\">   83.5664</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00007</td><td>TERMINATED</td><td>127.0.0.1:14864</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.555954</td><td style=\"text-align: right;\">   78.1671</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00008</td><td>TERMINATED</td><td>127.0.0.1:11544</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.381619</td><td style=\"text-align: right;\">   86.3583</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00009</td><td>TERMINATED</td><td>127.0.0.1:7204 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.30207 </td><td style=\"text-align: right;\">   89.2157</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00010</td><td>TERMINATED</td><td>127.0.0.1:18172</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.459787</td><td style=\"text-align: right;\">   82.63  </td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "<tr><td>train_hsr_4103c_00011</td><td>TERMINATED</td><td>127.0.0.1:15584</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.365432</td><td style=\"text-align: right;\">   89.3689</td><td style=\"text-align: right;\">                   7</td></tr>\n",
              "<tr><td>train_hsr_4103c_00012</td><td>TERMINATED</td><td>127.0.0.1:9560 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.44245 </td><td style=\"text-align: right;\">   88.8869</td><td style=\"text-align: right;\">                   7</td></tr>\n",
              "<tr><td>train_hsr_4103c_00013</td><td>TERMINATED</td><td>127.0.0.1:2996 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.300252</td><td style=\"text-align: right;\">   90.0735</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00014</td><td>TERMINATED</td><td>127.0.0.1:18448</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.316217</td><td style=\"text-align: right;\">   89.1108</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00015</td><td>TERMINATED</td><td>127.0.0.1:9824 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">0.426858</td><td style=\"text-align: right;\">   89.0972</td><td style=\"text-align: right;\">                   7</td></tr>\n",
              "<tr><td>train_hsr_4103c_00016</td><td>TERMINATED</td><td>127.0.0.1:7100 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.307833</td><td style=\"text-align: right;\">   89.7029</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00017</td><td>TERMINATED</td><td>127.0.0.1:12992</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.306959</td><td style=\"text-align: right;\">   89.4608</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00018</td><td>TERMINATED</td><td>127.0.0.1:21596</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">0.02  </td><td style=\"text-align: right;\">0.304777</td><td style=\"text-align: right;\">   89.4608</td><td style=\"text-align: right;\">                   2</td></tr>\n",
              "<tr><td>train_hsr_4103c_00019</td><td>TERMINATED</td><td>127.0.0.1:2008 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">          300</td><td style=\"text-align: right;\">0.0025</td><td style=\"text-align: right;\">0.438319</td><td style=\"text-align: right;\">   85.2143</td><td style=\"text-align: right;\">                   1</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-14 20:44:37,504\tINFO tune.py:626 -- Total run time: 437.31 seconds (436.49 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial config: {'d_embedding': 256, 'lr': 0.01, 'batch_size': 64}\n",
            "Best trial final validation loss: 0.2939215717362423\n",
            "Best trial final validation accuracy: 89.43491288727405\n"
          ]
        }
      ],
      "source": [
        "hyperparameter_search(config,num_samples=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocMC6wv1d0gw"
      },
      "source": [
        "### Best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUSYmza6d0gw"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "## Dataloaders\n",
        "training_dataloader = DataLoader(training_dataset, batch_size = BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plYfpmvyd0gx"
      },
      "outputs": [],
      "source": [
        "model1 = AveragingModel(256, len(en_vocab))\n",
        "model1 = model1.to(device)\n",
        "# Create an optimizer\n",
        "opt = optim.Adam(model1.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
        "# The criterion is a binary cross entropy loss based on logits - meaning that the sigmoid is integrated into the criterion\n",
        "# pos_weight = torch.tensor([9]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld4VGny8d0gx",
        "outputId": "ec76b202-1680-4d08-bac6-aa60d747209b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning training...\n",
            "Epoch 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0955, training acc: 96.6302: 100%|██████████| 406/406 [00:04<00:00, 98.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5103, Validation acc: 87.8769\n",
            "Epoch 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0892, training acc: 96.8065: 100%|██████████| 406/406 [00:04<00:00, 96.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5636, Validation acc: 87.9385\n",
            "INFO: Early stopping counter 1 of 5\n",
            "Epoch 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0811, training acc: 97.0312: 100%|██████████| 406/406 [00:04<00:00, 95.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5959, Validation acc: 87.5077\n",
            "INFO: Early stopping counter 2 of 5\n",
            "Epoch 4:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0774, training acc: 97.2421: 100%|██████████| 406/406 [00:04<00:00, 87.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6431, Validation acc: 87.8154\n",
            "INFO: Early stopping counter 3 of 5\n",
            "Epoch 5:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0724, training acc: 97.3738: 100%|██████████| 406/406 [00:04<00:00, 91.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.6892, Validation acc: 87.7538\n",
            "INFO: Early stopping counter 4 of 5\n",
            "Epoch 6:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training loss: 0.0694, training acc: 97.5754: 100%|██████████| 406/406 [00:04<00:00, 92.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.7322, Validation acc: 87.3538\n",
            "INFO: Early stopping counter 5 of 5\n",
            "INFO: Early stopping\n",
            "Test loss: 0.7870, Test acc: 88.2000\n"
          ]
        }
      ],
      "source": [
        "losses = experiment(model1, opt, criterion,num_epochs=20,use_early_stopping=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEXYTaUVd0gy"
      },
      "source": [
        "## Inspect model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxFXjJxnd0gy"
      },
      "outputs": [],
      "source": [
        "def hate_speech_recognition(text,model):\n",
        "    text_dataset = TextClassificationDataset([text],[0],en_vocab)\n",
        "    text_dataloader = DataLoader(text_dataset, batch_size = 1)\n",
        "    x,y = next(iter(text_dataloader))\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(x)\n",
        "        ## less than 0 -> non hate (class 0)\n",
        "        ## else Hate -> (class 1)\n",
        "        ## since there is no sigmoid acivation in the last layer \n",
        "        text_class = (pred>0)\n",
        "    result = text_class[0].item()\n",
        "    \n",
        "    ## print results\n",
        "    if result:\n",
        "        print(\"hate speech detected\")\n",
        "    else:\n",
        "        print(\"non hate speech\")\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWDEuEBHd0gz"
      },
      "outputs": [],
      "source": [
        "model1 = model1.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5mjFN7qd0gz",
        "outputId": "fda6b761-a778-408d-d7d2-5b1450120cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hate speech detected\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hate_speech_recognition(\"I hate you\",model=model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9ZMw4tad0g0"
      },
      "outputs": [],
      "source": [
        "def inspect_model(model, evalloader):\n",
        "    model.eval()\n",
        "    false_positive = []\n",
        "    false_negative = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(evalloader):\n",
        "            pred = model(x)\n",
        "            text_class = (pred>0)\n",
        "            \n",
        "            if text_class != y:\n",
        "                result = text_class[0].item()\n",
        "                if result:\n",
        "                    false_positive.append(i)\n",
        "                else:\n",
        "                    false_negative.append(i)\n",
        "    return false_positive,false_negative\n",
        "\n",
        "\n",
        "inspect_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle=False)\n",
        "false_positive,false_negative = inspect_model(model1,inspect_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9jCwvuSd0g0",
        "outputId": "b10208d6-7b41-4ab1-a59c-236368a90f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "179\n"
          ]
        }
      ],
      "source": [
        "print(len(false_positive))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IopQ-H1d0g1"
      },
      "source": [
        "### False Hate (false Positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaO8H8h3d0g1",
        "outputId": "37bd7bbb-de14-458e-a82b-269e50b0aa23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hate speech detected\n",
            "PLAIN text:\n",
            "Ombudsman\n",
            "\n",
            "is there for for Wiki?\n",
            "\n",
            "beckjord\n",
            "\n",
            "TOKENIZED TEXT:\n",
            "['ombudsman', 'wiki', 'beckjord']\n",
            "\n",
            "Predicted:  Hate\n",
            "True Label:  Non hate\n",
            "hate speech detected\n",
            "PLAIN text:\n",
            "Thanks! ) \n",
            "\n",
            "Hi, just wanted to let you know that I think you're a total loser to be patrolling recent changes.  Go outside and do us all a favor.\n",
            "Note: you ARE being reported for vandalism  stop it.\n",
            "\n",
            "TOKENIZED TEXT:\n",
            "['thank', 'want', 'let', 'know', 'think', 'total', 'loser', 'patrol', 'recent', 'chang', 'outsid', 'favor', 'note', 'report', 'vandal', 'stop']\n",
            "\n",
            "Predicted:  Hate\n",
            "True Label:  Non hate\n"
          ]
        }
      ],
      "source": [
        "## false Positive\n",
        "for i in false_positive[14:16]:\n",
        "    text = test_x.iloc[i]\n",
        "    pred_label = hate_speech_recognition(text,model=model1)\n",
        "    true_label = test_y.iloc[i]\n",
        "    print(\"PLAIN text:\")\n",
        "    print(text)\n",
        "    print()\n",
        "    print(\"TOKENIZED TEXT:\")\n",
        "    print(clean_and_tokenize(text))\n",
        "    print()\n",
        "    print(\"Predicted: \",\"Hate\" if pred_label else \"Non hate\")\n",
        "    print(\"True Label: \",\"Hate\" if true_label==1 else \"Non hate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CZBAh6zd0g2"
      },
      "source": [
        "### False Non Hate (false Negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ0Gc4Ond0g2",
        "outputId": "b3ec003c-31d4-44ad-b838-bb781428f645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "non hate speech\n",
            "PLAIN text:\n",
            "Definition of fat- Lauren Lozano!\n",
            "\n",
            "TOKENIZED TEXT:\n",
            "['definit', 'fat', 'lauren', 'lozano']\n",
            "\n",
            "Predicted:  Non hate\n",
            "True Label:  Hate\n"
          ]
        }
      ],
      "source": [
        "## false Negative\n",
        "for i in false_negative[32:33]:\n",
        "    text = test_x.iloc[i]\n",
        "    pred_label = hate_speech_recognition(text,model=model1)\n",
        "    true_label = test_y.iloc[i]\n",
        "    print(\"PLAIN text:\")\n",
        "    print(text)\n",
        "    print()\n",
        "    print(\"TOKENIZED TEXT:\")\n",
        "    print(clean_and_tokenize(text))\n",
        "    print()\n",
        "    print(\"Predicted: \",\"Hate\" if pred_label else \"Non hate\")\n",
        "    print(\"True Label: \",\"Hate\" if true_label==1 else \"Non hate\")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "9b432319b1b054266bcdf59eb764237d3d3272012fbf9a2e21780dc801e4d991"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('tf': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}